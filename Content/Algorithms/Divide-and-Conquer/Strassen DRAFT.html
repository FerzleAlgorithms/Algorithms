<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Strassen's Matrix Multiplication</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="/Algorithms/scripts/chapterScripts.js"></script>
  <link rel="stylesheet" href="/Algorithms/css/style.css">
  <link rel="stylesheet" href="/Algorithms/css/chapter.css">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-DQ5LVZVFDC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-DQ5LVZVFDC');
  </script>
</head>
<body>
  <h1>Strassen's Matrix Multiplication</h1>

  <section id="problem-solved">
  <h2>Problem Solved</h2>
    <p>
    Strassen's algorithm is a divide-and-conquer algorithm that solves the
    <a class="problem" href="?path=Problems%2FFoundational%2FMatrix%20Multiplication">Matrix Multiplication</a>
    problem. Somewhat surprisingly, it outperforms the classical \(O(n^3)\) algorithm by reducing the number of multiplications using a clever formula.
  </p>
  </section>

  <section id="design">
  <h2>Design and Strategy</h2>
  <p>
    Strassen's algorithm start exactly the same way as the standard <a class="problem" href="?path=Algorithms%2FDivide-and-Conquer%2FMatrix%20Multiplication"
>divide-and-conquer matrix multiplication</a> by partitioning each \(n\times n\) matrix into four \(n/2\times n/2\) blocks:
    \[A = \begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix}, \quad 
      B = \begin{pmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{pmatrix}.\]
   However, instead of computing the four \(C_{ij}\) blocks using 8 recursive products, Strassen's algorithm computes seven carefully chosen products \(M_1, M_2,\ldots, M_7\) of  \(n/2\times n/2\) matrices, and then forms the \(C\) blocks by linear combinations of the \(M\)'s. Although doing this once only saves one multiplication, the savings compound recursively, yielding an asymptotic running time of about \(O(n^{\log_2(7)}) \approx O(n^{2.81})\) (which we will justify later).
  </p>

  <p>Strassen's method forms seven auxiliary block products, \(M_1, \ldots, M_7.\) These products are chosen as particular linear combinations of the four \(A\)-blocks and four \(B\)-blocks so that (1) only seven recursive multiplications are needed and (2) appropriate linear combinations of the \(M_i\) reproduce the four \(C\) blocks via many cancellations. Define</p>
  <p>
    <begin{align*}
      M_1 &= (A_{11} + A_{22})(B_{11} + B_{22}) \\
      M_2 &= (A_{21} + A_{22})B_{11} \\
      M_3 &= A_{11}(B_{12} - B_{22}) \\
      M_4 &= A_{22}(B_{21} - B_{11}) \\
      M_5 &= (A_{11} + A_{12})B_{22} \\
      M_6 &= (A_{21} - A_{11})(B_{11} + B_{12}) \\
      M_7 &= (A_{12} - A_{22})(B_{21} + B_{22})
    \end{align*}
  </p>

  <p>Assemble the result by taking specific linear combinations of the \(M_i\); the pairwise cancellations in these combinations recover the usual block products for \(C\):</p>
    <p>
    <begin{align*}
      C_{11} &= M_1 + M_4 - M_5 + M_7\\
      C_{12} &= M_3 + M_5\\
      C_{21} &= M_2 + M_4\\
      C_{22} &= M_1 - M_2 + M_3 + M_6.
    \end{align*}
  </p>

  <p>
    At first glance it is not obvious why these particular combinations of the seven products produce the same blocks as the standard block formula. To see why, substitute the definitions of the \(M_i\) and expand for \(C_{11}\):
  </p>

  <p>
    \[
      \begin{aligned}
        M_1 &= (A_{11}+A_{22})(B_{11}+B_{22}) = A_{11}B_{11}+A_{11}B_{22}+A_{22}B_{11}+A_{22}B_{22},\\
        M_4 &= A_{22}(B_{21}-B_{11}) = A_{22}B_{21}-A_{22}B_{11},\\
        M_5 &= (A_{11}+A_{12})B_{22} = A_{11}B_{22}+A_{12}B_{22},\\
        M_7 &= (A_{12}-A_{22})(B_{21}+B_{22}) = A_{12}B_{21}+A_{12}B_{22}-A_{22}B_{21}-A_{22}B_{22}.
      \end{aligned}
    \]
  </p>

  <p>
    Now sum them as in the assembly formula:
    \[
      \begin{aligned}
        M_1 + M_4 - M_5 + M_7
        &= (\; A_{11}B_{11} + {\color{red} A_{11}B_{22}} + {\color{blue}A_{22}B_{11}} + {\color{green} A_{22}B_{22}} \;) \\
        &\quad +\; (\; {\color{orange}A_{22}B_{21}} - {\color{blue} A_{22}B_{11}} \;) \\
        &\quad -\; (\; {\color{red} A_{11}B_{22}} + {\color{purple} A_{12}B_{22}} \;) \\
        &\quad +\;(\; A_{12}B_{21} + {\color{purple} A_{12}B_{22}} - {\color{orange} A_{22}B_{21}} - {\color{green} A_{22}B_{22}} \;) \\
        &= A_{11}B_{11} + A_{12}B_{21},
      \end{aligned}
    \]
    where many terms cancel pairwise by design (see the matched colors above and verify they all cancel with thier counterpart). Thus the Strassen combination for \(C_{11}\) equals the usual block product.
  </p>

  <p>
    You should confirm the remaining three identities similarly; for reference, the standard block formulas are:
    <div class="highlight">
    \begin{align*}
C_{11} &= A_{11}B_{11}+A_{12}B_{21}\\
C_{12} &= A_{11}B_{12}+A_{12}B_{22}\\
C_{21} &= A_{21}B_{11}+A_{22}B_{21}\\
C_{22} &= A_{21}B_{12}+A_{22}B_{22}
    \end{align*}

    </div>
  </p>

  <p><strong>Size & padding:</strong> Strassen is usually presented assuming \(n = 2^k.\) For other sizes, pad to the next power of two and trim the result; the correctness is preserved in the top-left \(n\times n\) block, with only modest overhead in practice.</p>

  <div class="example-box">
    <strong class="example-title">Example: 2×2 matrices</strong>
    <p>Here is a tiny example of Strassen's algorithm in action. Let
    \[A=\begin{pmatrix}1 & 2\\ 3 & 4\end{pmatrix},\quad B=\begin{pmatrix}5 & 6\\ 7 & 8\end{pmatrix}.\]</p>

    <p>Compute the seven scalars (here blocks are scalars):</p>
    <p>
    \begin{align*}
      M_1 &= (A_{11}+A_{22})(B_{11}+B_{22}) \;=\; (1+4)(5+8) \;=\; 5\cdot 13 \;=\; 65\\
      M_2 &= (A_{21}+A_{22})B_{11} \;=\; (3+4)\cdot 5 \;=\; 7\cdot 5 \;=\; 35\\
      M_3 &= A_{11}(B_{12}-B_{22}) \;=\; 1\cdot(6-8) \;=\; 1\cdot(-2) \;=\; -2\\
      M_4 &= A_{22}(B_{21}-B_{11}) \;=\; 4\cdot(7-5) \;=\; 4\cdot 2 \;=\; 8\\
      M_5 &= (A_{11}+A_{12})B_{22} \;=\; (1+2)\cdot 8 \;=\; 3\cdot 8 \;=\; 24\\
      M_6 &= (A_{21}-A_{11})(B_{11}+B_{12}) \;=\; (3-1)(5+6) \;=\; 2\cdot 11 \;=\; 22\\
      M_7 &= (A_{12}-A_{22})(B_{21}+B_{22}) \;=\; (2-4)(7+8) \;=\; (-2)\cdot 15 \;=\; -30
    \end{align*}
    </p>

    <p>Assemble:</p>
    <p>
    \begin{align*}
      C_{11} &= M_1 + M_4 - M_5 + M_7 \;=\; 65 + 8 - 24 - 30 \;=\; 19\\
      C_{12} &= M_3 + M_5 \;=\; -2 + 24 \;=\; 22\\
      C_{21} &= M_2 + M_4 \;=\; 35 + 8 \;=\; 43\\
      C_{22} &= M_1 - M_2 + M_3 + M_6 \;=\; 65 - 35 - 2 + 22 \;=\; 50
    \end{align*}
    </p>

    <p>Putting the 4 numbers in place, we get the final answer:
      \(\begin{pmatrix}19 & 22\\ 43 & 50\end{pmatrix}\). You should double check the answer by doing the matrix product using the definition and comparing.</p>

  </div>

    <p>The previous example only involved \(2\times 2\) matrices, so it was quite simple. For larger matrices, computation of each \(M_i\) involves a multiplication on \(n/2\times n/2\) submatrices, which are also performed using the same procedure.This leads to the following high-level pseudocode:
  </p>
  <ol>
    <li>Base case: If size=1, compute directly.</li>
    <li>Recursive case: Partition \(A\) and \(B\), compute the seven \(M_i\) (using additions/subtractions of blocks and recursive calls), then assemble \(C\) from the \(M\)'s.</li>
  </ol>
  </section>

  <p>The following demo shows an implementation of the algorithm that allows you to see the recursive aspect of it in action. It allows you to show or skip some of the computations. It is recommended that you show enough of them until you understand what is going on. Then feel free to skip some of the steps.</p>
  <section id="demo">
  <div class="embeddedDemoContainer">
    <iframe class="embeddedDemo"
            src="/Algorithms/Content/Demos/Divide-and-Conquer/Strassens Demo.html"
            allow="fullscreen"
            name="strassen-demo">
    </iframe>
  </div>
  </section>

  <section id="code">
  <h2>Implementation in Java, C++, Python</h2>
  <p>Below are straightforward, unoptimized implementations provided for clarity. Production code would optimize memory allocation, reuse temporaries, and apply cache-aware blocking. The examples use a <code>THRESHOLD</code>: when submatrix sizes fall at or below this threshold the algorithm switches from recursive Strassen to the standard (brute‑force) multiply because the recursion overhead outweighs the benefit for small matrices.</p>

  <div class="tab-group">
    <div class="tabs" role="tablist">
      <button id="tab-java" class="tablink active" data-lang="java" role="tab" aria-controls="java" aria-selected="true">Java</button>
      <button id="tab-cpp" class="tablink" data-lang="cpp" role="tab" aria-controls="cpp" aria-selected="false">C++</button>
      <button id="tab-python" class="tablink" data-lang="python" role="tab" aria-controls="python" aria-selected="false">Python</button>
    </div>

    <div id="java" class="code-container active" role="tabpanel" aria-labelledby="tab-java">
      <pre><code class="language-java">// When n &lt;= THRESHOLD, switch to standard multiply to avoid recursion overhead
static final int THRESHOLD = 64;

/** Classical O(n^3) multiply helper used as the recursion base case */
private static int[][] standardMultiply(int[][] A, int[][] B) {
    int n = A.length;
    int[][] C = new int[n][n];
    for (int i = 0; i &lt; n; i++)
        for (int j = 0; j &lt; n; j++)
            for (int k = 0; k &lt; n; k++)
                C[i][j] += A[i][k] * B[k][j];
    return C;
}

/** Matrix addition helper: elementwise add two same-size square matrices */
private static int[][] add(int[][] A, int[][] B) {
    int n = A.length;
    int[][] C = new int[n][n];
    for (int i = 0; i &lt; n; i++)
        for (int j = 0; j &lt; n; j++)
            C[i][j] = A[i][j] + B[i][j];
    return C;
}

/** Matrix subtraction helper: elementwise subtract B from A */
private static int[][] sub(int[][] A, int[][] B) {
    int n = A.length;
    int[][] C = new int[n][n];
    for (int i = 0; i &lt; n; i++)
        for (int j = 0; j &lt; n; j++)
            C[i][j] = A[i][j] - B[i][j];
    return C;
}

/** Strassen multiply (assumes n is power of 2).
 *  Base case: for small n use classical O(n^3) multiply.
 *  Recursive case: split into four n/2 blocks, compute seven Strassen products (M1..M7),
 *  then assemble C from the linear combinations.
 */
public static int[][] strassenMultiply(int[][] A, int[][] B) {
    int n = A.length;
    if (n &lt;= THRESHOLD) {
        return standardMultiply(A, B);
    }
    int newSize = n / 2;
    // allocate submatrices for A and B (A11,A12,A21,A22 and B11,...)
    int[][] A11 = new int[newSize][newSize], A12 = new int[newSize][newSize],
            A21 = new int[newSize][newSize], A22 = new int[newSize][newSize];
    int[][] B11 = new int[newSize][newSize], B12 = new int[newSize][newSize],
            B21 = new int[newSize][newSize], B22 = new int[newSize][newSize];
    // copy entries into submatrices
    for (int i = 0; i &lt; newSize; i++) {
        for (int j = 0; j &lt; newSize; j++) {
            A11[i][j] = A[i][j];
            A12[i][j] = A[i][j + newSize];
            A21[i][j] = A[i + newSize][j];
            A22[i][j] = A[i + newSize][j + newSize];
            B11[i][j] = B[i][j];
            B12[i][j] = B[i][j + newSize];
            B21[i][j] = B[i + newSize][j];
            B22[i][j] = B[i + newSize][j + newSize];
        }
    }
    // compute the seven Strassen products (each is a recursive call)
    int[][] M1 = strassenMultiply(add(A11, A22), add(B11, B22));
    int[][] M2 = strassenMultiply(add(A21, A22), B11);
    int[][] M3 = strassenMultiply(A11, sub(B12, B22));
    int[][] M4 = strassenMultiply(A22, sub(B21, B11));
    int[][] M5 = strassenMultiply(add(A11, A12), B22);
    int[][] M6 = strassenMultiply(sub(A21, A11), add(B11, B12));
    int[][] M7 = strassenMultiply(sub(A12, A22), add(B21, B22));
    // assemble final blocks using the Strassen recombination formulas
    int[][] C = new int[n][n];
    int[][] C11 = add(sub(add(M1, M4), M5), M7);  // M1 + M4 - M5 + M7
    int[][] C12 = add(M3, M5);                    // M3 + M5
    int[][] C21 = add(M2, M4);                    // M2 + M4
    int[][] C22 = add(sub(add(M1, M3), M2), M6);  // M1 - M2 + M3 + M6
    for (int i = 0; i &lt; newSize; i++) {
        for (int j = 0; j &lt; newSize; j++) {
            C[i][j] = C11[i][j];
            C[i][j + newSize] = C12[i][j];
            C[i + newSize][j] = C21[i][j];
            C[i + newSize][j + newSize] = C22[i][j];
        }
    }
    return C;
}
</code></pre>
    </div>

    <div id="cpp" class="code-container" role="tabpanel" aria-labelledby="tab-cpp">
      <pre><code class="language-cpp">// Matrix is a square vector-of-vectors of ints
using Matrix = std::vector&lt;std::vector&lt;int&gt;&gt;;
const int THRESHOLD = 64; // switch to classical multiply at or below this size

// classical O(n^3) multiply used as the recursion base case
Matrix standard_mult(const Matrix &A, const Matrix &B) {
    int n = A.size();
    Matrix C(n, std::vector&lt;int&gt;(n, 0));
    for (int i = 0; i &lt; n; ++i)
        for (int j = 0; j &lt; n; ++j)
            for (int k = 0; k &lt; n; ++k)
                C[i][j] += A[i][k] * B[k][j];
    return C;
}

// elementwise addition helper
Matrix add(const Matrix &A, const Matrix &B) {
    int n = A.size();
    Matrix C(n, std::vector&lt;int&gt;(n));
    for (int i = 0; i &lt; n; ++i)
        for (int j = 0; j &lt; n; ++j)
            C[i][j] = A[i][j] + B[i][j];
    return C;
}
// elementwise subtraction helper
Matrix sub(const Matrix &A, const Matrix &B) {
    int n = A.size();
    Matrix C(n, std::vector&lt;int&gt;(n));
    for (int i = 0; i &lt; n; ++i)
        for (int j = 0; j &lt; n; ++j)
            C[i][j] = A[i][j] - B[i][j];
    return C;
}

Matrix strassen(const Matrix &A, const Matrix &B) {
    int n = A.size();
    if (n &lt;= THRESHOLD) {
        return standard_mult(A, B);
    }
    int m = n/2;
    // split A and B into 4 blocks each (copying for clarity)
    Matrix A11(m, std::vector&lt;int&gt;(m)), A12(m, std::vector&lt;int&gt;(m)),
           A21(m, std::vector&lt;int&gt;(m)), A22(m, std::vector&lt;int&gt;(m));
    Matrix B11(m, std::vector&lt;int&gt;(m)), B12(m, std::vector&lt;int&gt;(m)),
           B21(m, std::vector&lt;int&gt;(m)), B22(m, std::vector&lt;int&gt;(m));
    for (int i = 0; i &lt; m; ++i)
      for (int j = 0; j &lt; m; ++j) {
        A11[i][j] = A[i][j];
        A12[i][j] = A[i][j+m];
        A21[i][j] = A[i+m][j];
        A22[i][j] = A[i+m][j+m];
        B11[i][j] = B[i][j];
        B12[i][j] = B[i][j+m];
        B21[i][j] = B[i+m][j];
        B22[i][j] = B[i+m][j+m];
      }
    // seven Strassen products (recursive)
    Matrix M1 = strassen(add(A11,A22), add(B11,B22));
    Matrix M2 = strassen(add(A21,A22), B11);
    Matrix M3 = strassen(A11, sub(B12,B22));
    Matrix M4 = strassen(A22, sub(B21,B11));
    Matrix M5 = strassen(add(A11,A12), B22);
    Matrix M6 = strassen(sub(A21,A11), add(B11,B12));
    Matrix M7 = strassen(sub(A12,A22), add(B21,B22));
    // assemble final matrix from block combinations
    Matrix C(n, std::vector&lt;int&gt;(n));
    Matrix C11 = add(sub(add(M1,M4), M5), M7);  // M1 + M4 - M5 + M7
    Matrix C12 = add(M3, M5);                    // M3 + M5
    Matrix C21 = add(M2, M4);                    // M2 + M4
    Matrix C22 = add(sub(add(M1,M3), M2), M6);   // M1 - M2 + M3 + M6
    for (int i = 0; i &lt; m; ++i)
      for (int j = 0; j &lt; m; ++j) {
        C[i][j] = C11[i][j];
        C[i][j+m] = C12[i][j];
        C[i+m][j] = C21[i][j];
        C[i+m][j+m] = C22[i][j];
      }
    return C;
}
</code></pre>
    </div>

    <div id="python" class="code-container" role="tabpanel" aria-labelledby="tab-python">
      <pre><code class="language-python">THRESHOLD = 64  # switch to classical multiply at or below this size

def add(A, B):
    "Elementwise addition of two square matrices A and B."
    n = len(A)
    return [[A[i][j] + B[i][j] for j in range(n)] for i in range(n)]

def sub(A, B):
    "Elementwise subtraction A - B."
    n = len(A)
    return [[A[i][j] - B[i][j] for j in range(n)] for i in range(n)]

def standard_mult(A, B):
    "Classical O(n^3) matrix multiplication used as the recursion base case."
    n = len(A)
    C = [[0]*n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            for k in range(n):
                C[i][j] += A[i][k] * B[k][j]
    return C

def strassen(A, B):
    """
    Strassen's algorithm:
    - If n &lt;= THRESHOLD use standard_mult.
    - Otherwise split A and B into 4 submatrices, compute M1..M7 recursively,
      and combine to form the result blocks.
    """
    n = len(A)
    if n &lt;= THRESHOLD:
        return standard_mult(A, B)
    m = n // 2
    # create submatrices (copying for clarity)
    A11 = [[A[i][j] for j in range(m)] for i in range(m)]
    A12 = [[A[i][j+m] for j in range(m)] for i in range(m)]
    A21 = [[A[i+m][j] for j in range(m)] for i in range(m)]
    A22 = [[A[i+m][j+m] for j in range(m)] for i in range(m)]
    B11 = [[B[i][j] for j in range(m)] for i in range(m)]
    B12 = [[B[i][j+m] for j in range(m)] for i in range(m)]
    B21 = [[B[i+m][j] for j in range(m)] for i in range(m)]
    B22 = [[B[i+m][j+m] for j in range(m)] for i in range(m)]
    # seven products (recursive)
    M1 = strassen(add(A11, A22), add(B11, B22))
    M2 = strassen(add(A21, A22), B11)
    M3 = strassen(A11, sub(B12, B22))
    M4 = strassen(A22, sub(B21, B11))
    M5 = strassen(add(A11, A12), B22)
    M6 = strassen(sub(A21, A11), add(B11, B12))
    M7 = strassen(sub(A12, A22), add(B21, B22))
    # assemble blocks
    C11 = add(sub(add(M1, M4), M5), M7)  // M1 + M4 - M5 + M7
    C12 = add(M3, M5)                    // M3 + M5
    C21 = add(M2, M4)                    // M2 + M4
    C22 = add(sub(add(M1, M3), M2), M6)  // M1 - M2 + M3 + M6
    # join into full matrix
    C = [[0]*n for _ in range(n)]
    for i in range(m):
        for j in range(m):
            C[i][j] = C11[i][j]
            C[i][j+m] = C12[i][j]
            C[i+m][j] = C21[i][j]
            C[i+m][j+m] = C22[i][j]
    return C
</code></pre>
    </div>
  </div>
  </section>

  <section id="analysis">
  <h2>Time/Space Analysis</h2>

  <p>
    <strong>Time Complexity:</strong> Each call to Strassen's algorithm performs seven recursive calls on matrices of size \(n/2\) and a collection of matrix additions/subtractions of cost \(O(n^2)\) to form the operands and to assemble the result. Hence the running time satisfies
    \[
      T(n) = 7\,T(n/2) + \Theta(n^2).
    \]
    Applying the Master Theorem with \(a = 7\), \(b = 2\), and \(d=2\), we obtain 
    \[T(n) = \Theta(n^{\log_2 7}) \approx \Theta(n^{2.80735}).\]
    By contrast, the classical (naive) algorithm performs takes \(O(n^3)\) time. As \(n\) grows, Strassen's algorithm becomes significantly faster than the classical method.
  </p>

  <p>
    But we can be a little more specific and count the number of additions and the number of multiplications. This can be useful to compare Strassen with other algorithms, especially the brute-force and naive divide-and-conquer algorithm.
    First, we let \(M(n)\) denote the number of scalar multiplications. Each recursive call creates seven subproblems of size \(n/2\), and no scalar multiplications are performed in the combine phase beyond those produced by recursive calls. When \(n=1\), two number are finally multiplied (so one multiplication is performed). Thus
    \[
      M(n) = 7\,M(n/2),\qquad M(1)=1,
    \]
    and therefore
    \[
      M(n) = O(n^{\log_2 7}) \approx O(n^{2.80735}).
    \]
  </p>

  <p>
    Next, we count the number of scalar additions/subtractions.
    Let \(A(n)\) denote the number of scalar additions/subtractions. 
    To form the seven operand matrices, we perform 10 matrix additions/subtractions of size \((n/2)\times(n/2)\); to assemble the four result blocks from \(M_1\ldots M_7\) we do 8 matrix additions/subtractions of size \((n/2)\times(n/2)\). That is a total of 18 matrix adds/subs per call, for a total of \(18(n/2)^2\) additions/subtractions. 
    When \(n=1\), no additions/subtractions are performed (so \(A(1)=0\)).
    Thus, 
    \[
      A(n) = 7\,A(n/2) + 18\cdot\Big(\frac{n}{2}\Big)^2 = 7\,A(n/2) + \frac{18}{4}\,n^2.
    \]
    As with \(M(n)\), the Master Theorem yields a solution of    
    \[
      A(n) = O(n^{\log_2 7}) \approx O(n^{2.80735}).
    \]
  </p>
  <p>Since the constants involved with Strassen's algorithm are not insignificant, it is important to do a more precise computation of number of operations and/or test implementations to determine for which values of \(n\) Strassen's algorithm is practially more efficient than the brute-force algorithm. We will leave that the the activities/problems.</p>

    <p>
      <font style="color: red; font-weight: bold; font-size: 3em;">I AM HERE!!!!</font><br> 
    <strong>Space Complexity:</strong> Because of the recursive calls, computing the amount of memory used takes a little effort.
        For each recursive call, 19 matrices of half the size are stored (This can be easily reduced to 11 by using offsets
        in recursive calls, but we will leave it to the reader to think about how to do that), along with the final result 
        of the same size. 
        Thus, during the first recrusive call, the memory used is \(n^2+19 (\frac{n}{2})^2 = 23 (\frac{n}{2})^2\). 
        When a recursive call is made, that allocates 19 matrices of size \(\frac{n}{4}\times\frac{n}{4}\) and one 
        of size \(\frac{n}{2}\times\frac{n}{2}\), for a total of \(23 (\frac{n}{4})^2\) space; and so on. 
        This leads to a geometric series of memory usage across recursion levels:
        
    \begin{align*}
      \text{Peak_Memory}(n) &= 23\Big(\frac{n}{2}\Big)^2 + 23\Big(\frac{n}{4}\Big)^2 + 23\Big(\frac{n}{8}\Big)^2 + \cdots 23(1)^2\\
          &= 23\; n^2\sum_{i=1}^{\log_4(n)}\Big(\frac{1}{4}\Big)^i \\
          &\leq 23\; n^2\sum_{i=0}^{\infty}\Big(\frac{1}{4}\Big)^i \\
          &=23\; n^2 \frac{1}{1-1/4} \\
          &= \frac{92}{3}\,n^2,
    \end{align*}
        so total memory usage is \(\Theta(n^2)\).</p>
    <p>This analysis assumes temporary memory used in each recursive call is freed before sibling recursive calls begin. If the seven recursive multiplications run concurrently (parallel Strassen) or if temporaries are retained across calls, memory usage grows with concurrency and can be much larger than \(\Theta(n^2)\).</p>

</section>

  <section id="variations">
  <h2>Variations/Improvements</h2>
  <ul>
    <li>Hybrid approaches: switch to standard multiplication below a threshold for better constants and stability.</li>
    <li>Memory-optimized Strassen: reuse temporaries and avoid allocating many small matrices at each recursion level.</li>
    <li>Further asymptotic improvements exist (e.g., Coppersmith–Winograd and successors) but are rarely practical due to huge constants.</li>
    <li>Parallel Strassen: the 7 recursive calls give parallelism; practical gains depend on task granularity and memory bandwidth.</li>
  </ul>
  </section>

  <section id="links">
  <h2>Links to Resources</h2>
  <ul>
    <li><a href="https://en.wikipedia.org/wiki/Strassen_algorithm" target="_blank">Strassen algorithm (Wikipedia)</a></li>
    <li><a href="https://www.geeksforgeeks.org/strassen-algorithm-for-matrix-multiplication/" target="_blank">Strassen's algorithm (GeeksforGeeks)</a></li>
  </ul>
  </section>

 <section id="reading-questions">
  <h2>Reading Comprehension Questions</h2>
  <ol>
    <li>Write the seven Strassen products M1..M7 and the formulas for C11..C22. Why do they produce the same result as standard multiplication?</li>
    <li>Give the recurrence for Strassen's running time and solve it using the Master Theorem.</li>
    <li>Explain why Strassen reduces the number of multiplications and what is being traded off.</li>
    <li>When might standard O(n^3) or blocked algorithms be preferable to Strassen?</li>
    <li>Discuss numerical stability concerns with Strassen and one mitigation strategy.</li>
    <li>How does padding to a power-of-two affect correctness and asymptotic runtime?</li>
    <li>Describe how to combine Strassen with blocking/cache-aware optimizations.</li>
  </ol>

  <button id="toggleAnswers" class="show-answer" aria-expanded="false">Show Answers</button>
  <div id="answers" class="answer" hidden>
    <ol>
      <li><strong>Answer:</strong> See M1..M7 and assembly formulas above; correctness follows because the block algebra expands to the usual sum over k when blocks are treated as matrix entries.</li>
      <li><strong>Answer:</strong> T(n)=7T(n/2)+O(n^2), so T(n)=Θ(n^{log_2 7}) ≈ Θ(n^{2.81}).</li>
      <li><strong>Answer:</strong> Strassen replaces one multiplication per recursion level with several additions/subtractions; since multiplications dominate cost, this reduces asymptotic work.</li>
      <li><strong>Answer:</strong> For small n, high constants, and stability concerns; blocked classical methods often beat Strassen in practice for medium sizes.</li>
      <li><strong>Answer:</strong> More additions can amplify round-off error; use higher-precision arithmetic or hybrid switching to standard multiply at lower levels.</li>
      <li><strong>Answer:</strong> Padding preserves correctness in the top-left block and increases runtime only by a constant factor; asymptotic bound remains the same.</li>
      <li><strong>Answer:</strong> Use Strassen at outer recursion levels, switch to blocked classical multiply in the leaves, and reuse temporaries to reduce allocations.</li>
    </ol>
  </div>
</section>

<section id="activities">
  <h2>In-Class Activities</h2>
  <ol>
    <li>Derive the M1..M7 formulas algebraically by expanding block products and grouping terms. <em>Deliverable:</em> short derivation showing equivalence to block-by-block formula.</li>
    <li>Small-group numeric exercise: apply Strassen to a 4×4 problem by partitioning into 2×2 blocks and using Strassen on the 2×2 blocks (compute M1..M7 where blocks are 2×2 matrices). <em>Deliverable:</em> hand-computed block results and assembled C.</li>
    <li>Implement Strassen and compare runtime vs. blocked classical multiply for sizes n in {128,256,512}. Report crossover point (threshold) and memory use. <em>Deliverable:</em> short experiment writeup and plots.</li>
    <li>Sketch parallel task graph for the seven recursive multiplications and estimate theoretical parallelism; discuss practical limits due to memory bandwidth.</li>
  </ol>
</section>

  <section id="problems">
    <h2>Homework Problems</h2>
    <ol>
      <li><strong>Strassen correctness:</strong> Prove algebraically that the Strassen formulas recover the usual block multiplication by expanding block products.</li>

      <li><strong>Operation counts:</strong> Let M(n) be scalar multiplications and A(n) additions in Strassen. Write recurrences for \(M\) and A, solve asymptotically, and compare to classical methods.</li>

      <li><strong>Hybrid implementation:</strong> Implement Strassen with a switch to blocked classical multiplication below a threshold. Empirically determine the best threshold on your machine and explain why.</li>

      <li><strong>Numerical stability study:</strong> Compare relative error of Strassen vs. classical multiply on random floating-point matrices of varying condition numbers. Summarize findings and discuss mitigation strategies.</li>

      <li><strong>Padding and non-power-of-two:</strong> Describe padding strategy for arbitrary p×q times q×r multiplication using Strassen, and analyze overhead. Provide pseudocode.</li>

      <li><strong>Parallel Strassen:</strong> Sketch a parallel implementation that spawns the seven recursive products concurrently. Using the work/span model, give W(n) and S(n) and estimate maximum parallelism.</li>
    </ol>
  </section>

</body>
</html>
