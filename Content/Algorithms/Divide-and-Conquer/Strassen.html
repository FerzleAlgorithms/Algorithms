<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Strassen's Matrix Multiplication</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="/Algorithms/scripts/chapterScripts.js"></script>
  <link rel="stylesheet" href="/Algorithms/css/style.css">
  <link rel="stylesheet" href="/Algorithms/css/chapter.css">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-DQ5LVZVFDC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-DQ5LVZVFDC');
  </script>
</head>
<body>
  <h1>Strassen's Matrix Multiplication</h1>

  <section id="problem-solved">
  <h2>Problem Solved</h2>
    <p>
    Strassen's algorithm is a divide-and-conquer algorithm that solves the
    <a class="problem" href="?path=Problems%2FFoundational%2FMatrix%20Multiplication">Matrix Multiplication</a>
    problem. Somewhat surprisingly, it outperforms the classical \(O(n^3)\) algorithm by reducing the number of multiplications using a clever formula.
  </p>
  </section>

  <section id="design">
  <h2>Design and Strategy</h2>
  <p>
    Strassen's algorithm starts exactly the same way as the standard <a class="problem" href="?path=Algorithms%2FDivide-and-Conquer%2FMatrix%20Multiplication"
>divide-and-conquer matrix multiplication</a> by partitioning each \(n\times n\) matrix into four \(n/2\times n/2\) blocks:
    \[A = \begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix}, \quad 
      B = \begin{pmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{pmatrix}.\]
   However, instead of computing the four \(C_{ij}\) blocks using 8 recursive products, Strassen's algorithm computes seven carefully chosen products \(M_1, M_2,\ldots, M_7\) of  \(n/2\times n/2\) matrices, and then forms the \(C\) blocks by linear combinations of the \(M\)'s. Although doing this once only saves one multiplication, the savings compound recursively, yielding an asymptotic running time of about \(O(n^{\log_2(7)}) \approx O(n^{2.81})\) (which we will justify later).
  </p>

  <p>Strassen's method forms seven auxiliary block products, \(M_1, \ldots, M_7.\) These products are chosen as particular linear combinations of the four \(A\)-blocks and four \(B\)-blocks so that (1) only seven recursive multiplications are needed and (2) appropriate linear combinations of the \(M_i\) reproduce the four \(C\) blocks via many cancellations. Define</p>
  <p>
    \begin{align*}
      M_1 &= (A_{11} + A_{22})(B_{11} + B_{22}) \\
      M_2 &= (A_{21} + A_{22})B_{11} \\
      M_3 &= A_{11}(B_{12} - B_{22}) \\
      M_4 &= A_{22}(B_{21} - B_{11}) \\
      M_5 &= (A_{11} + A_{12})B_{22} \\
      M_6 &= (A_{21} - A_{11})(B_{11} + B_{12}) \\
      M_7 &= (A_{12} - A_{22})(B_{21} + B_{22})
    \end{align*}
  </p>

  <p>Assemble the result by taking specific linear combinations of the \(M_i\); the pairwise cancellations in these combinations recover the usual block products for \(C\):</p>
    <p>
    \begin{align*}
      C_{11} &= M_1 + M_4 - M_5 + M_7\\
      C_{12} &= M_3 + M_5\\
      C_{21} &= M_2 + M_4\\
      C_{22} &= M_1 - M_2 + M_3 + M_6.
    \end{align*}
  </p>

  <p>
    At first glance it is not obvious why these particular combinations of the seven products produce the same blocks as the standard block formula. To see why, substitute the definitions of the \(M_i\) and expand for \(C_{11}\):
  </p>

  <p>
    \[
      \begin{aligned}
        M_1 &= (A_{11}+A_{22})(B_{11}+B_{22}) = A_{11}B_{11}+A_{11}B_{22}+A_{22}B_{11}+A_{22}B_{22},\\
        M_4 &= A_{22}(B_{21}-B_{11}) = A_{22}B_{21}-A_{22}B_{11},\\
        M_5 &= (A_{11}+A_{12})B_{22} = A_{11}B_{22}+A_{12}B_{22},\\
        M_7 &= (A_{12}-A_{22})(B_{21}+B_{22}) = A_{12}B_{21}+A_{12}B_{22}-A_{22}B_{21}-A_{22}B_{22}.
      \end{aligned}
    \]
  </p>

  <p>
    Now sum them as in the assembly formula:
    \[
      \begin{aligned}
        M_1 + M_4 - M_5 + M_7
        &= (\; A_{11}B_{11} + {\color{red} A_{11}B_{22}} + {\color{blue}A_{22}B_{11}} + {\color{green} A_{22}B_{22}} \;) \\
        &\quad +\; (\; {\color{orange}A_{22}B_{21}} - {\color{blue} A_{22}B_{11}} \;) \\
        &\quad -\; (\; {\color{red} A_{11}B_{22}} + {\color{purple} A_{12}B_{22}} \;) \\
        &\quad +\;(\; A_{12}B_{21} + {\color{purple} A_{12}B_{22}} - {\color{orange} A_{22}B_{21}} - {\color{green} A_{22}B_{22}} \;) \\
        &= A_{11}B_{11} + A_{12}B_{21},
      \end{aligned}
    \]
    where many terms cancel pairwise by design (see the matched colors above and verify they all cancel with their counterpart). Thus the Strassen combination for \(C_{11}\) equals the usual block product.
  </p>

  <p>
    You should confirm the remaining three identities similarly; for reference, the standard block formulas are:
    <div class="highlight">
    \begin{align*}
C_{11} &= A_{11}B_{11}+A_{12}B_{21}\\
C_{12} &= A_{11}B_{12}+A_{12}B_{22}\\
C_{21} &= A_{21}B_{11}+A_{22}B_{21}\\
C_{22} &= A_{21}B_{12}+A_{22}B_{22}
    \end{align*}

    </div>
  </p>

  <p><strong>Size & padding:</strong> Strassen is usually presented assuming \(n = 2^k.\) For other sizes, pad to the next power of two and trim the result; the correctness is preserved in the top-left \(n\times n\) block, with only modest overhead in practice.</p>

  <div class="example-box">
    <strong class="example-title">Example: \(2\times 2\) matrices</strong>
    <p>Here is a tiny example of Strassen's algorithm in action. Let
    \[A=\begin{pmatrix}1 & 2\\ 3 & 4\end{pmatrix},\quad B=\begin{pmatrix}5 & 6\\ 7 & 8\end{pmatrix}.\]</p>

    <p>Compute the seven scalars (here blocks are scalars):</p>
    <p>
    \begin{align*}
      M_1 &= (A_{11}+A_{22})(B_{11}+B_{22}) \;=\; (1+4)(5+8) \;=\; 5\cdot 13 \;=\; 65\\
      M_2 &= (A_{21}+A_{22})B_{11} \;=\; (3+4)\cdot 5 \;=\; 7\cdot 5 \;=\; 35\\
      M_3 &= A_{11}(B_{12}-B_{22}) \;=\; 1\cdot(6-8) \;=\; 1\cdot(-2) \;=\; -2\\
      M_4 &= A_{22}(B_{21}-B_{11}) \;=\; 4\cdot(7-5) \;=\; 4\cdot 2 \;=\; 8\\
      M_5 &= (A_{11}+A_{12})B_{22} \;=\; (1+2)\cdot 8 \;=\; 3\cdot 8 \;=\; 24\\
      M_6 &= (A_{21}-A_{11})(B_{11}+B_{12}) \;=\; (3-1)(5+6) \;=\; 2\cdot 11 \;=\; 22\\
      M_7 &= (A_{12}-A_{22})(B_{21}+B_{22}) \;=\; (2-4)(7+8) \;=\; (-2)\cdot 15 \;=\; -30
    \end{align*}
    </p>

    <p>Assemble:</p>
    <p>
    \begin{align*}
      C_{11} &= M_1 + M_4 - M_5 + M_7 \;=\; 65 + 8 - 24 - 30 \;=\; 19\\
      C_{12} &= M_3 + M_5 \;=\; -2 + 24 \;=\; 22\\
      C_{21} &= M_2 + M_4 \;=\; 35 + 8 \;=\; 43\\
      C_{22} &= M_1 - M_2 + M_3 + M_6 \;=\; 65 - 35 - 2 + 22 \;=\; 50
    \end{align*}
    </p>

    <p>Putting the 4 numbers in place, we get the final answer:
      \(\begin{pmatrix}19 & 22\\ 43 & 50\end{pmatrix}\). You should double check the answer by doing the matrix product using the definition and comparing.</p>

  </div>

    <p>The previous example only involved \(2\times 2\) matrices, so it was quite simple. For larger matrices, computation of each \(M_i\) involves a multiplication on \(n/2\times n/2\) submatrices, which are also performed using the same procedure.This leads to the following high-level pseudocode:
  </p>
  <ol>
    <li>Base case: If size=1, compute directly.</li>
    <li>Recursive case: Partition \(A\) and \(B\), compute the seven \(M_i\) (using additions/subtractions of blocks and recursive calls), then assemble \(C\) from the \(M\)'s.</li>
  </ol>
  </section>

  <p>The following demo shows an implementation of the algorithm that allows you to see the recursive aspect of it in action. It allows you to show or skip some of the computations. It is recommended that you show enough of them until you understand what is going on. Then feel free to skip some of the steps.</p>
  <section id="demo">
  <div class="embeddedDemoContainer">
    <iframe class="embeddedDemo"
            src="/Algorithms/Content/Demos/Divide-and-Conquer/Strassens Demo.html"
            allow="fullscreen"
            name="strassen-demo">
    </iframe>
  </div>
  </section>

  <section id="code">
  <h2>Implementation in Java, C++, Python</h2>
  <p>Below are straightforward, unoptimized implementations provided for clarity. Production code would optimize memory allocation, reuse temporaries, and apply cache-aware blocking. The examples use a <code>THRESHOLD</code>: when submatrix sizes fall at or below this threshold the algorithm switches from recursive Strassen to the standard (bruteâ€‘force) multiply because the recursion overhead outweighs the benefit for small matrices.</p>

  <div class="tab-group">
    <div class="tabs" role="tablist">
      <button id="tab-java" class="tablink active" data-lang="java" role="tab" aria-controls="java" aria-selected="true">Java</button>
      <button id="tab-cpp" class="tablink" data-lang="cpp" role="tab" aria-controls="cpp" aria-selected="false">C++</button>
      <button id="tab-python" class="tablink" data-lang="python" role="tab" aria-controls="python" aria-selected="false">Python</button>
    </div>

    <div id="java" class="code-container active" role="tabpanel" aria-labelledby="tab-java">
      <pre><code class="language-java">// When n &lt;= THRESHOLD, switch to standard multiply to avoid recursion overhead
static final int THRESHOLD = 64;

/** Classical O(n^3) multiply helper used as the recursion base case */
private static int[][] standardMultiply(int[][] A, int[][] B) {
    int n = A.length;
    int[][] C = new int[n][n];
    for (int i = 0; i &lt; n; i++)
        for (int j = 0; j &lt; n; j++)
            for (int k = 0; k &lt; n; k++)
                C[i][j] += A[i][k] * B[k][j];
    return C;
}

/** Matrix addition helper: elementwise add two same-size square matrices */
private static int[][] add(int[][] A, int[][] B) {
    int n = A.length;
    int[][] C = new int[n][n];
    for (int i = 0; i &lt; n; i++)
        for (int j = 0; j &lt; n; j++)
            C[i][j] = A[i][j] + B[i][j];
    return C;
}

/** Matrix subtraction helper: elementwise subtract B from A */
private static int[][] sub(int[][] A, int[][] B) {
    int n = A.length;
    int[][] C = new int[n][n];
    for (int i = 0; i &lt; n; i++)
        for (int j = 0; j &lt; n; j++)
            C[i][j] = A[i][j] - B[i][j];
    return C;
}

/** Strassen multiply (assumes n is power of 2).
 *  Base case: for small n use classical O(n^3) multiply.
 *  Recursive case: split into four n/2 blocks, compute seven Strassen products (M1..M7),
 *  then assemble C from the linear combinations.
 */
public static int[][] strassenMultiply(int[][] A, int[][] B) {
    int n = A.length;
    if (n &lt;= THRESHOLD) {
        return standardMultiply(A, B);
    }
    int newSize = n / 2;
    // allocate submatrices for A and B (A11,A12,A21,A22 and B11,...)
    int[][] A11 = new int[newSize][newSize], A12 = new int[newSize][newSize],
            A21 = new int[newSize][newSize], A22 = new int[newSize][newSize];
    int[][] B11 = new int[newSize][newSize], B12 = new int[newSize][newSize],
            B21 = new int[newSize][newSize], B22 = new int[newSize][newSize];
    // copy entries into submatrices
    for (int i = 0; i &lt; newSize; i++) {
        for (int j = 0; j &lt; newSize; j++) {
            A11[i][j] = A[i][j];
            A12[i][j] = A[i][j + newSize];
            A21[i][j] = A[i + newSize][j];
            A22[i][j] = A[i + newSize][j + newSize];
            B11[i][j] = B[i][j];
            B12[i][j] = B[i][j + newSize];
            B21[i][j] = B[i + newSize][j];
            B22[i][j] = B[i + newSize][j + newSize];
        }
    }
    // compute the seven Strassen products (each is a recursive call)
    int[][] M1 = strassenMultiply(add(A11, A22), add(B11, B22));
    int[][] M2 = strassenMultiply(add(A21, A22), B11);
    int[][] M3 = strassenMultiply(A11, sub(B12, B22));
    int[][] M4 = strassenMultiply(A22, sub(B21, B11));
    int[][] M5 = strassenMultiply(add(A11, A12), B22);
    int[][] M6 = strassenMultiply(sub(A21, A11), add(B11, B12));
    int[][] M7 = strassenMultiply(sub(A12, A22), add(B21, B22));
    // assemble final blocks using the Strassen recombination formulas
    int[][] C = new int[n][n];
    int[][] C11 = add(sub(add(M1, M4), M5), M7);  // M1 + M4 - M5 + M7
    int[][] C12 = add(M3, M5);                    // M3 + M5
    int[][] C21 = add(M2, M4);                    // M2 + M4
    int[][] C22 = add(sub(add(M1, M3), M2), M6);  // M1 - M2 + M3 + M6
    for (int i = 0; i &lt; newSize; i++) {
        for (int j = 0; j &lt; newSize; j++) {
            C[i][j] = C11[i][j];
            C[i][j + newSize] = C12[i][j];
            C[i + newSize][j] = C21[i][j];
            C[i + newSize][j + newSize] = C22[i][j];
        }
    }
    return C;
}
</code></pre>
    </div>

    <div id="cpp" class="code-container" role="tabpanel" aria-labelledby="tab-cpp">
      <pre><code class="language-cpp">// Matrix is a square vector-of-vectors of ints
using Matrix = std::vector&lt;std::vector&lt;int&gt;&gt;;
const int THRESHOLD = 64; // switch to classical multiply at or below this size

// classical O(n^3) multiply used as the recursion base case
Matrix standard_mult(const Matrix &A, const Matrix &B) {
    int n = A.size();
    Matrix C(n, std::vector&lt;int&gt;(n, 0));
    for (int i = 0; i &lt; n; ++i)
        for (int j = 0; j &lt; n; ++j)
            for (int k = 0; k &lt; n; ++k)
                C[i][j] += A[i][k] * B[k][j];
    return C;
}

// elementwise addition helper
Matrix add(const Matrix &A, const Matrix &B) {
    int n = A.size();
    Matrix C(n, std::vector&lt;int&gt;(n));
    for (int i = 0; i &lt; n; ++i)
        for (int j = 0; j &lt; n; ++j)
            C[i][j] = A[i][j] + B[i][j];
    return C;
}
// elementwise subtraction helper
Matrix sub(const Matrix &A, const Matrix &B) {
    int n = A.size();
    Matrix C(n, std::vector&lt;int&gt;(n));
    for (int i = 0; i &lt; n; ++i)
        for (int j = 0; j &lt; n; ++j)
            C[i][j] = A[i][j] - B[i][j];
    return C;
}

Matrix strassen(const Matrix &A, const Matrix &B) {
    int n = A.size();
    if (n &lt;= THRESHOLD) {
        return standard_mult(A, B);
    }
    int m = n/2;
    // split A and B into 4 blocks each (copying for clarity)
    Matrix A11(m, std::vector&lt;int&gt;(m)), A12(m, std::vector&lt;int&gt;(m)),
           A21(m, std::vector&lt;int&gt;(m)), A22(m, std::vector&lt;int&gt;(m));
    Matrix B11(m, std::vector&lt;int&gt;(m)), B12(m, std::vector&lt;int&gt;(m)),
           B21(m, std::vector&lt;int&gt;(m)), B22(m, std::vector&lt;int&gt;(m));
    for (int i = 0; i &lt; m; ++i)
      for (int j = 0; j &lt; m; ++j) {
        A11[i][j] = A[i][j];
        A12[i][j] = A[i][j+m];
        A21[i][j] = A[i+m][j];
        A22[i][j] = A[i+m][j+m];
        B11[i][j] = B[i][j];
        B12[i][j] = B[i][j+m];
        B21[i][j] = B[i+m][j];
        B22[i][j] = B[i+m][j+m];
      }
    // seven Strassen products (recursive)
    Matrix M1 = strassen(add(A11,A22), add(B11,B22));
    Matrix M2 = strassen(add(A21,A22), B11);
    Matrix M3 = strassen(A11, sub(B12,B22));
    Matrix M4 = strassen(A22, sub(B21,B11));
    Matrix M5 = strassen(add(A11,A12), B22);
    Matrix M6 = strassen(sub(A21,A11), add(B11,B12));
    Matrix M7 = strassen(sub(A12,A22), add(B21,B22));
    // assemble final matrix from block combinations
    Matrix C(n, std::vector&lt;int&gt;(n));
    Matrix C11 = add(sub(add(M1,M4), M5), M7);  // M1 + M4 - M5 + M7
    Matrix C12 = add(M3, M5);                    // M3 + M5
    Matrix C21 = add(M2, M4);                    // M2 + M4
    Matrix C22 = add(sub(add(M1,M3), M2), M6);   // M1 - M2 + M3 + M6
    for (int i = 0; i &lt; m; ++i)
      for (int j = 0; j &lt; m; ++j) {
        C[i][j] = C11[i][j];
        C[i][j+m] = C12[i][j];
        C[i+m][j] = C21[i][j];
        C[i+m][j+m] = C22[i][j];
      }
    return C;
}
</code></pre>
    </div>

    <div id="python" class="code-container" role="tabpanel" aria-labelledby="tab-python">
      <pre><code class="language-python">THRESHOLD = 64  # switch to classical multiply at or below this size

def add(A, B):
    "Elementwise addition of two square matrices A and B."
    n = len(A)
    return [[A[i][j] + B[i][j] for j in range(n)] for i in range(n)]

def sub(A, B):
    "Elementwise subtraction A - B."
    n = len(A)
    return [[A[i][j] - B[i][j] for j in range(n)] for i in range(n)]

def standard_mult(A, B):
    "Classical O(n^3) matrix multiplication used as the recursion base case."
    n = len(A)
    C = [[0]*n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            for k in range(n):
                C[i][j] += A[i][k] * B[k][j]
    return C

def strassen(A, B):
    """
    Strassen's algorithm:
    - If n &lt;= THRESHOLD use standard_mult.
    - Otherwise split A and B into 4 submatrices, compute M1..M7 recursively,
      and combine to form the result blocks.
    """
    n = len(A)
    if n &lt;= THRESHOLD:
        return standard_mult(A, B)
    m = n // 2
    # create submatrices (copying for clarity)
    A11 = [[A[i][j] for j in range(m)] for i in range(m)]
    A12 = [[A[i][j+m] for j in range(m)] for i in range(m)]
    A21 = [[A[i+m][j] for j in range(m)] for i in range(m)]
    A22 = [[A[i+m][j+m] for j in range(m)] for i in range(m)]
    B11 = [[B[i][j] for j in range(m)] for i in range(m)]
    B12 = [[B[i][j+m] for j in range(m)] for i in range(m)]
    B21 = [[B[i+m][j] for j in range(m)] for i in range(m)]
    B22 = [[B[i+m][j+m] for j in range(m)] for i in range(m)]
    # seven products (recursive)
    M1 = strassen(add(A11, A22), add(B11, B22))
    M2 = strassen(add(A21, A22), B11)
    M3 = strassen(A11, sub(B12, B22))
    M4 = strassen(A22, sub(B21, B11))
    M5 = strassen(add(A11, A12), B22)
    M6 = strassen(sub(A21, A11), add(B11, B12))
    M7 = strassen(sub(A12, A22), add(B21, B22))
    # assemble blocks
    C11 = add(sub(add(M1, M4), M5), M7)  # M1 + M4 - M5 + M7
    C12 = add(M3, M5)                    # M3 + M5
    C21 = add(M2, M4)                    # M2 + M4
    C22 = add(sub(add(M1, M3), M2), M6)  # M1 - M2 + M3 + M6
    # join into full matrix
    C = [[0]*n for _ in range(n)]
    for i in range(m):
        for j in range(m):
            C[i][j] = C11[i][j]
            C[i][j+m] = C12[i][j]
            C[i+m][j] = C21[i][j]
            C[i+m][j+m] = C22[i][j]
    return C
</code></pre>
    </div>
  </div>
  </section>

  <section id="analysis">
  <h2>Time/Space Analysis</h2>

  <p>
    <strong>Time Complexity:</strong> Each call to Strassen's algorithm performs seven recursive calls on matrices of size \(n/2\) and a collection of matrix additions/subtractions of cost \(O(n^2)\) to form the operands and to assemble the result. Hence the running time satisfies
    \[
      T(n) = 7\,T(n/2) + \Theta(n^2).
    \]
    Applying the Master Theorem with \(a = 7\), \(b = 2\), and \(d=2\), we obtain 
    \[T(n) = \Theta(n^{\log_2 7}) \approx \Theta(n^{2.80735}).\]
    By contrast, the classical (naive) algorithm performs takes \(O(n^3)\) time. As \(n\) grows, Strassen's algorithm becomes significantly faster than the classical method.
  </p>

  <p>
    But we can be a little more specific and count the number of additions and the number of multiplications. This can be useful to compare Strassen with other algorithms, especially the brute-force and naive divide-and-conquer algorithm.
    First, we let \(M(n)\) denote the number of scalar multiplications. Each recursive call creates seven subproblems of size \(n/2\), and no scalar multiplications are performed in the combine phase beyond those produced by recursive calls. When \(n=1\), two number are finally multiplied (so one multiplication is performed). Thus
    \[
      M(n) = 7\,M(n/2),\qquad M(1)=1,
    \]
    and therefore
    \[
      M(n) = O(n^{\log_2 7}) \approx O(n^{2.80735}).
    \]
  </p>

  <p>
    Next, we count the number of scalar additions/subtractions.
    Let \(A(n)\) denote the number of scalar additions/subtractions. 
    To form the seven operand matrices, we perform 10 matrix additions/subtractions of size \((n/2)\times(n/2)\); to assemble the four result blocks from \(M_1\ldots M_7\) we do 8 matrix additions/subtractions of size \((n/2)\times(n/2)\). That is a total of 18 matrix adds/subs per call, for a total of \(18(n/2)^2\) additions/subtractions. 
    When \(n=1\), no additions/subtractions are performed (so \(A(1)=0\)).
    Thus, 
    \[
      A(n) = 7\,A(n/2) + 18\cdot\Big(\frac{n}{2}\Big)^2 = 7\,A(n/2) + \frac{18}{4}\,n^2.
    \]
    As with \(M(n)\), the Master Theorem yields a solution of    
    \[
      A(n) = O(n^{\log_2 7}) \approx O(n^{2.80735}).
    \]
  </p>
  <p>Since the constants involved with Strassen's algorithm are not insignificant, it is important to do a more precise computation of number of operations and/or test implementations to determine for which values of \(n\) Strassen's algorithm is practically more efficient than the brute-force algorithm. We will leave that the the activities/problems.</p>

    <p>
    <strong>Space Complexity:</strong> Because of the recursive calls, computing the exact amount of memory used takes a little effort. We will leave it to an exercise to fill in the details, but the amount of extra space used by Strassen's algorithm is \(\Theta(n^2)\).
    </p>
</section>

  <section id="variations">
  <h2>Variations/Improvements</h2>
  <ul>
    <li><strong>Hybrid cutoff (THRESHOLD):</strong> Benchmark on target hardware and switch to a blocked classical multiply at/under the cutoff (often 32â€“256). Use separate cutoffs per datatype.</li>
    <li><strong>Winograd variant:</strong> Use Strassenâ€“Winograd schedules to reduce additions (fewer matrix adds than vanilla Strassen) while keeping 7 multiplies; improves constant factors.</li>
    <li><strong>Memory reuse and in-place schedules:</strong> Reuse 2â€“3 scratch buffers to compute \(M_1\ldots, M_7\) and assemble \(C_{ij}\), avoiding per-level allocations. 
      A scratch pool keeps peak extra memory near \(O(n^2)\).</li>
    <li><strong>Numerical stability:</strong> Perform additions/subtractions in higher precision (e.g., float64 for float32 inputs). For integers, use 64-bit accumulators to avoid overflow.</li>
    <li><strong>Parallel Strassen:</strong> Fork the 7 recursive multiplies up to a depth cutoff; use a work-stealing pool. Limit parallelism to avoid memory-bandwidth saturation and oversubscription.</li>
  </ul>
  </section>

  <section id="links">
  <h2>Links to Resources</h2>
  <ul>
    <li><a href="https://en.wikipedia.org/wiki/Strassen_algorithm" target="_blank">Strassen algorithm (Wikipedia)</a> Discussion of Strassen's algorithm, including a link to the original paper.</li>
    <li><a href="https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm" target="_blank">Matrix Multiplication Algorithm (Wikipedia)</a> Discussion of several matrix multiplication algorithms.</li>
    <li><a href="https://www.geeksforgeeks.org/dsa/strassens-matrix-multiplication/" target="_blank">Matrix Multiplication (GeeksforGeeks)</a> Several algorithms, including Strassen's.</li>
  </ul>
  </section>

  <section id="reading-questions">
  <h2>Reading Comprehension Questions</h2>
  <ol>
    <li><strong>Big idea:</strong> In one sentence, how does Strassen differ from standard divide-and-conquer matrix multiplication?</li>
    <li><strong>Seven products:</strong> Write the definitions of \(M_1,\ldots,M_7\). Then expand \(C_{11}=M_1+M_4-M_5+M_7\) and show the cancellations to get \(A_{11}B_{11}+A_{12}B_{21}\).</li>
    <li><strong>Recurrence & exponent:</strong> Give the runtime recurrence for Strassen and solve it with the Master Theorem. State \(\log_2 7\) to 5 decimal places.</li>
    <li><strong>Operation counts:</strong> Let \(M(n)\) be the number of scalar multiplications and \(A(n)\) the number of scalar additions/subtractions in Strassen. Write the recurrences (with base cases) and give their asymptotic solutions. Briefly explain (one sentence) why \(A(n)\) is not \(\Theta(n^2\log n)\).</li>
    <li><strong>Base case / cutoff:</strong> What purpose does a <code>THRESHOLD</code> (hybrid switch to classical multiply) serve, and why can it make Strassen faster in practice?</li>
    <li><strong>Padding:</strong> When \(n\) is not a power of two, what size do we pad the matrices to, and where is the correct \(n\times n\) product located after padding and multiplication?</li>
    <li><strong>Space:</strong> What is the extra-space complexity of a straightforward Strassen implementation and what causes it? Name one strategy that keeps peak extra space at \(\Theta(n^2)\).</li>
  </ol>

  <button id="toggleAnswers" class="show-answer" aria-expanded="false">Show Answers</button>
  <div id="answers" class="answer" hidden>
    <ol>
      <li><strong>Answer:</strong> It reduces the 8 sub-matrix multiplications to 7 by forming linear combinations of blocks, then recombines those 7 results to recover the 4 output blocks.</li>
      <li><strong>Answer:</strong> Use the listed \(M_i\) formulas; expanding \(C_{11}=M_1+M_4-M_5+M_7\) cancels to \(A_{11}B_{11}+A_{12}B_{21}\) as shown in the text.</li>
      <li><strong>Answer:</strong> \(T(n)=7T(n/2)+\Theta(n^2)\); by Master Theorem, \(T(n)=\Theta(n^{\log_2 7})\) with \(\log_2 7\approx 2.80735\).</li>
      <li><strong>Answer:</strong> \(M(n)=7M(n/2),\;M(1)=1\Rightarrow M(n)=\Theta(n^{\log_2 7})\).  
        \(A(n)=7A(n/2)+18\,(n/2)^2,\;A(1)=0\Rightarrow A(n)=\Theta(n^{\log_2 7})\).  
        Because \(a=7>b^d=2^2=4\), the recursive part dominates (Master Theorem case 1), not the \(\Theta(n^2)\) term.</li>
      <li><strong>Answer:</strong> It avoids small, overhead-dominated recursion; below the cutoff, classical \(O(n^3)\) is faster due to better constants and cache use.</li>
      <li><strong>Answer:</strong> Pad to the smallest value of \(k\) such that \(n\leq 2^k\); the correct result is in the top-left \(n\times n\) block.</li>
      <li><strong>Answer:</strong> \(\Theta(n^2)\) extra space from temporary block sums/differences and storing intermediates \(M_1\ldots M_7\). Reuse a small scratch buffer / in-place schedules to cap peak memory at \(\Theta(n^2)\).</li>
    </ol>
  </div>
</section>


<section id="activities">
  <h2>In-Class Activities</h2>
  <ol>
    <li><strong>Correctness of Strassen's Algorithm:</strong> Verify the formulas used by Strassen's algorithm to show that it properly computes the matrix product.</li>
    <li><strong>Warm-up (\(2\times 2\) run):</strong> Using two \(2\times 2\) matrices provided by the instructor, compute \(M_1\ldots M_7\) and assemble \(C\).
      <em>Deliverable:</em> the seven scalars and the final \(2\times 2\) product. Compare your answers with others.</li>

    <li><strong>Block \(4\times 4\) run:</strong> Partition \(4\times 4\) matrices into \(2\times 2\) blocks and apply one level of Strassen (on \(2\times 2\) blocks).
      <em>Deliverable:</em> the seven \(2\times 2\) block products and the assembled \(4\times 4\) matrix \(C\).</li>

    <li><strong>Exact operation counts for \(n=2^k\):</strong>
        Let \(M(n)\) be the number of scalar multiplications and \(A(n)\) the number of scalar additions/subtractions in Strassen. 
      <ol type="a">
        <li>Write recurrences (with base cases) for \(M(n)\) and \(A(n)\) when \(n=2^k\).</li>
        <li>Make a small table for \(k=1,\ldots,6\) listing \(n=2^k\), \(M(n)\), and \(A(n)\).</li>
        <li>Solve the recurrences to closed form in terms of \(k\) (or \(n\)). <em>Hint:</em> one solves to a linear combination of \(7^k\) and \(4^k\), and the other one is really easy.</li>
        
      </ol>
    </li>

    <li><strong>Exact peak memory for the reference code:</strong>
      Assume the provided implementation that copies submatrices, computes all \(M_1\ldots M_7\) and keeps them until assembly, and builds \(C\) from four blocks.
      <ol type="a">
        <li>At the first level of recursion, list which submatrices must be <em>simultaneously</em> resident. State your assumptions about temporaries from <code>add</code>/<code>sub</code> and when they can be freed.</li>
        <li>Given the number of submatrices and their sizes, how much memory is 
          required at this level of recursion? (Remember that an \((n/2)\times(n/2)\) matrix requires \((n/2)^2\) scalars (numbers)).</li>
        <li>Repeat for the second level of recursion.</li>
        <li>Derive a geometric series for the total peak memory use along one recursion path (down to \(n=1\)).</li>
        <li>Simplify the geometric series and upper bound it  
          to show that the peak memory usage is \(O(n^2)\).</li>
        <li>Repeat the count assuming half as many matrices are required.
           Compare the memory usage of both scenarios.</li>
      </ol>
    </li>

    <li><strong>Cost-model crossover (analytic threshold):</strong>
      For a given algorithm \(\text{alg}\),
      let total cost be 
      \[C_{\text{alg}}(n)=c_a\cdot A(n)+c_m\cdot M(n)\] 
      where constants \(c_a,c_m&gt;0\) are relative weights of how much time addition
      and multiplication take. Assume \(n=2^k\) throughout.
      <ol type="a">
        <li>Write \(C_{\text{Strassen}}(n)\) using your closed forms for \(A(n),M(n)\).</li>
        <li>For the brute-force matrix multiplication, derive (or look up) exact counts for \(M(n)\) and \(A(n)\) and write \(C_{\text{brute}}(n)\).</li>
        <li>Plot \(C_{\text{brute}}(n)\) and \(C_{\text{Strassen}}(n)\) assuming 
          \(c_m=c_a=1\) (equal cost per mult/add) and determine the crossover point.</li>
        <li>Repeat for \(c_m=3\) and \(c_a=1\) (mults cost 3x adds), 
          and \(c_m=10\) and \(c_a=1\)  (mults cost 10x adds).</li>
      </ol>
    </li>

    <li><strong>Complex Number Multiplication Shortcut:</strong>
      Break into groups and determine how to multiply \((a+bi)(c+di)\) using only 3 real number multiplications. Derive the formula and count adds/mults.</li>
  </ol>
</section>

<section id="problems">
  <h2>Homework Problems</h2>
  <ol>
    <li><strong>Exact operation counts for \(n=2^k\):</strong>
      Let \(n=2^k\). Recall that \(M(n)\) is the number of scalar multiplications and \(A(n)\) as the number of scalar additions/subtractions in Strassen's algorithm.
      <ol type="a">
        <li>Find an exact closed-formula for \(M(n)\) and prove that it is correct.</li>
        <li>Find an exact closed-formula for \(A(n)\) and prove that it is correct.</li>
        <li>Verify your formulas by computing \(M(n)\) and \(A(n)\) for \(n\in\{2,4,8,16\}\) directly from the recursion tree and comparing with the formulas.</li>
      </ol>
    </li>

    <li><strong>Classical exact counts:</strong>
      For the classical triple-loop algorithm,
      <ol type="a">
        <li>Show that the exact number of scalar multiplications is \(n^3\).</li>
        <li>Show that the exact number of scalar additions is \(n^2(n-1)=n^3-n^2\).</li>
      </ol>
    </li>

    <li><strong>Exact peak memory for the reference code:</strong>
       Do In-Class Activity 5 above.
    </li>
    <li><strong>Cost-model crossover (analytic threshold):</strong>
       Do In-Class Activity 6 above.
    </li>

    <li><strong>Hands-on Strassen (\(4\times 4\) numbers):</strong>
      Use the matrices
      \[
      A=\begin{pmatrix}
      1&2&0&1\\ 0&1&2&0\\ 1&0&1&2\\ 2&1&0&1
      \end{pmatrix},\quad
      B=\begin{pmatrix}
      2&0&1&1\\ 1&1&0&2\\ 0&2&1&0\\ 1&0&2&1
      \end{pmatrix}.
      \]
      <ol type="a">
        <li>Partition into \(2\times 2\) blocks and compute one full level of Strassen (i.e., compute the seven \(2\times 2\) block products and assemble \(C\)). You may multiplethe \(2\times 2\) matrices using the brute-force algorithm.</li>
        <li>Verify your result by classical multiplication (you may use a computer to check).</li>
      </ol>
    </li>
  </ol>
</section>

</body>
</html>
