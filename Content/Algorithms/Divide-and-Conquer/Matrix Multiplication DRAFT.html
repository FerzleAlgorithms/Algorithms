<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Matrix Multiplication (Divide and Conquer)</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="/Algorithms/scripts/chapterScripts.js"></script>
  <link rel="stylesheet" href="/Algorithms/css/style.css">
  <link rel="stylesheet" href="/Algorithms/css/chapter.css">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-DQ5LVZVFDC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-DQ5LVZVFDC');
  </script>
</head>
<body>
  <h1>Matrix Multiplication (Divide and Conquer)</h1>

  <section id="problem-solved">
  <h2>Problem Solved</h2>
  <p>
    Matrix Multiplication (Divide and Conquer) solves the
    <a class="problem" href="?path=Problems%2FFoundational%2FMatrix%20Multiplication">Matrix Multiplication</a>
    problem using a divide-and-conquer approach. Although it turns out to not be more efficient than the brute-force algorithm we will see later, it provides a foundation for more advanced algorithms like Strassen's method. The divide-and-conquer strategy allows us to break down the problem of multiplying two \(n\times n\) matrices into smaller subproblems, which can be solved recursively.
  </p>
  </section>

  <section id="design">
  <h2>Design and Strategy</h2>
  <p>
    The divide-and-conquer approach to matrix multiplication recursively breaks down the problem of multiplying two \(n\times n\) matrices into smaller subproblems. Instead of using the standard \(O(n^3)\) algorithm that computes each entry using a dot product, we divide each matrix into four quadrants and use the mathematical property that matrix multiplication can be expressed in terms of operations on these quadrants.
  </p>
  
  <p><strong>Size Restriction:</strong> For simplicity, we assume \(n = 2^k\) for some integer \(k\), so matrices can be evenly divided. This ensures each recursive call works with matrices of size \(n/2 \times n/2\). Matrices of odd sizes or non-power-of-2 dimensions can be handled by padding with zeros to the next power of 2, though this introduces some overhead.</p>

  <p>
    For two \(n\times n\) matrices A and B, we partition them into four \(n/2 \times n/2\) submatrices each:
    \[A = \begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix}, \quad B = \begin{pmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{pmatrix}\]
    where each \(A_{ij}\) and \(B_{ij}\) is an \(n/2 \times n/2\) matrix.
  </p>
  
  <p>
    The product C = A × B can then be computed as:
    \[C = \begin{pmatrix} C_{11} & C_{12} \\ C_{21} & C_{22} \end{pmatrix}\]
    where each \(C_{ij}\) is also an \(n/2 \times n/2\) matrix given by:
    \[C_{11} = A_{11}B_{11} + A_{12}B_{21}\]
    \[C_{12} = A_{11}B_{12} + A_{12}B_{22}\]
    \[C_{21} = A_{21}B_{11} + A_{22}B_{21}\]
    \[C_{22} = A_{21}B_{12} + A_{22}B_{22}\]
  </p>

  <p><strong>Why This Formula Works:</strong> The key insight is that matrix multiplication follows the same algebraic rules whether we think of entries as scalars or as blocks (submatrices). To see why, recall that in standard matrix multiplication, entry \(C[i][j]\) is computed as:
  \[C[i][j] = \sum_{k=0}^{n-1} A[i][k] \cdot B[k][j]\]
  
  When we partition the matrices, this sum naturally splits based on which quadrant the indices fall into:</p>
  
  <ul>
    <li><strong>For \(C_{11}\):</strong> Entries where both \(i < n/2\) and \(j < n/2\). The sum decomposes as:
    \begin{align}
    C[i][j] &= \sum_{k=0}^{n-1} A[i][k] \cdot B[k][j] \\
    &= \sum_{k=0}^{n/2-1} A[i][k] \cdot B[k][j] + \sum_{k=n/2}^{n-1} A[i][k] \cdot B[k][j] \\
    &= (A_{11} \times B_{11})[i][j] + (A_{12} \times B_{21})[i][j]
    \end{align}
    The first sum uses the left half of row \(i\) from \(A\) with the top half of column \(j\) from \(B\), giving us the contribution from \(A_{11} \times B_{11}\). The second sum uses the right half of row \(i\) from \(A\) with the bottom half of column \(j\) from \(B\), giving us \(A_{12} \times B_{21}\).</li>
    
    <li><strong>For \(C_{12}\):</strong> Entries where \(i < n/2\) and \(j \geq n/2\). The sum decomposes as:
    \begin{align}
    C[i][j] &= \sum_{k=0}^{n-1} A[i][k] \cdot B[k][j] \\
    &= \sum_{k=0}^{n/2-1} A[i][k] \cdot B[k][j] + \sum_{k=n/2}^{n-1} A[i][k] \cdot B[k][j] \\
    &= (A_{11} \times B_{12})[i][j] + (A_{12} \times B_{22})[i][j]
    \end{align}
    Here we're using rows from the top half of \(A\) with columns from the right half of \(B\). The first sum gives us \(A_{11} \times B_{12}\) and the second gives us \(A_{12} \times B_{22}\).</li>
    
    <li><strong>Similarly:</strong> \(C_{21}\) and \(C_{22}\) follow the same pattern. For \(C_{21}\) (bottom-left quadrant), we get \(C_{21} = A_{21}B_{11} + A_{22}B_{21}\), and for \(C_{22}\) (bottom-right quadrant), we get \(C_{22} = A_{21}B_{12} + A_{22}B_{22}\).</li>
  </ul>

  <div class="example-box">
    <strong class="example-title">Detailed Example: 4×4 Matrix Multiplication</strong>
    <p>Let's multiply two 4×4 matrices using both approaches to see they produce identical results:</p>
    
    <p>
      \[A = \begin{pmatrix} 1 & 2 & 3 & 4 \\ 5 & 6 & 7 & 8 \\ 9 & 10 & 11 & 12 \\ 13 & 14 & 15 & 16 \end{pmatrix}, \quad B = \begin{pmatrix} 2 & 1 & 3 & 0 \\ 1 & 2 & 0 & 1 \\ 0 & 1 & 2 & 3 \\ 3 & 0 & 1 & 2 \end{pmatrix}\]
    </p>
    
    <p><strong>Step 1: Divide-and-Conquer Partitioning</strong></p>
    <p>First, we partition each matrix into four 2×2 submatrices:</p>
    
    <p>
      \[A_{11} = \begin{pmatrix} 1 & 2 \\ 5 & 6 \end{pmatrix}, \quad A_{12} = \begin{pmatrix} 3 & 4 \\ 7 & 8 \end{pmatrix}\]
      \[A_{21} = \begin{pmatrix} 9 & 10 \\ 13 & 14 \end{pmatrix}, \quad A_{22} = \begin{pmatrix} 11 & 12 \\ 15 & 16 \end{pmatrix}\]
    </p>
    
    <p>
      \[B_{11} = \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix}, \quad B_{12} = \begin{pmatrix} 3 & 0 \\ 0 & 1 \end{pmatrix}\]
      \[B_{21} = \begin{pmatrix} 0 & 1 \\ 3 & 0 \end{pmatrix}, \quad B_{22} = \begin{pmatrix} 2 & 3 \\ 1 & 2 \end{pmatrix}\]
    </p>
    
    <p><strong>Step 2: Compute \(C_{11} = A_{11}B_{11} + A_{12}B_{21}\)</strong></p>
    
    <p>First, \(A_{11}B_{11}\):</p>
    <p>\[\begin{pmatrix} 1 & 2 \\ 5 & 6 \end{pmatrix} \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix} = \begin{pmatrix} 1(2)+2(1) & 1(1)+2(2) \\ 5(2)+6(1) & 5(1)+6(2) \end{pmatrix} = \begin{pmatrix} 4 & 5 \\ 16 & 17 \end{pmatrix}\]</p>
    
    <p>Next, \(A_{12}B_{21}\):</p>
    <p>\[\begin{pmatrix} 3 & 4 \\ 7 & 8 \end{pmatrix} \begin{pmatrix} 0 & 1 \\ 3 & 0 \end{pmatrix} = \begin{pmatrix} 3(0)+4(3) & 3(1)+4(0) \\ 7(0)+8(3) & 7(1)+8(0) \end{pmatrix} = \begin{pmatrix} 12 & 3 \\ 24 & 7 \end{pmatrix}\]</p>
    
    <p>Therefore: \(C_{11} = \begin{pmatrix} 4 & 5 \\ 16 & 17 \end{pmatrix} + \begin{pmatrix} 12 & 3 \\ 24 & 7 \end{pmatrix} = \begin{pmatrix} 16 & 8 \\ 40 & 24 \end{pmatrix}\)</p>
    
    <p><strong>Step 3: Compute \(C_{12} = A_{11}B_{12} + A_{12}B_{22}\)</strong></p>
    
    <p>\(A_{11}B_{12} = \begin{pmatrix} 1 & 2 \\ 5 & 6 \end{pmatrix} \begin{pmatrix} 3 & 0 \\ 0 & 1 \end{pmatrix} = \begin{pmatrix} 3 & 2 \\ 15 & 6 \end{pmatrix}\)</p>
    
    <p>\(A_{12}B_{22} = \begin{pmatrix} 3 & 4 \\ 7 & 8 \end{pmatrix} \begin{pmatrix} 2 & 3 \\ 1 & 2 \end{pmatrix} = \begin{pmatrix} 10 & 17 \\ 22 & 37 \end{pmatrix}\)</p>
    
    <p>Therefore: \(C_{12} = \begin{pmatrix} 3 & 2 \\ 15 & 6 \end{pmatrix} + \begin{pmatrix} 10 & 17 \\ 22 & 37 \end{pmatrix} = \begin{pmatrix} 13 & 19 \\ 37 & 43 \end{pmatrix}\)</p>
    
    <p><strong>Step 4: Compute \(C_{21} = A_{21}B_{11} + A_{22}B_{21}\)</strong></p>
    
    <p>\(A_{21}B_{11} = \begin{pmatrix} 9 & 10 \\ 13 & 14 \end{pmatrix} \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix} = \begin{pmatrix} 28 & 29 \\ 40 & 41 \end{pmatrix}\)</p>
    
    <p>\(A_{22}B_{21} = \begin{pmatrix} 11 & 12 \\ 15 & 16 \end{pmatrix} \begin{pmatrix} 0 & 1 \\ 3 & 0 \end{pmatrix} = \begin{pmatrix} 36 & 11 \\ 48 & 15 \end{pmatrix}\)</p>
    
    <p>Therefore: \(C_{21} = \begin{pmatrix} 28 & 29 \\ 40 & 41 \end{pmatrix} + \begin{pmatrix} 36 & 11 \\ 48 & 15 \end{pmatrix} = \begin{pmatrix} 64 & 40 \\ 88 & 56 \end{pmatrix}\)</p>
    
    <p><strong>Step 5: Compute \(C_{22} = A_{21}B_{12} + A_{22}B_{22}\)</strong></p>
    
    <p>\(A_{21}B_{12} = \begin{pmatrix} 9 & 10 \\ 13 & 14 \end{pmatrix} \begin{pmatrix} 3 & 0 \\ 0 & 1 \end{pmatrix} = \begin{pmatrix} 27 & 10 \\ 39 & 14 \end{pmatrix}\)</p>
    
    <p>\(A_{22}B_{22} = \begin{pmatrix} 11 & 12 \\ 15 & 16 \end{pmatrix} \begin{pmatrix} 2 & 3 \\ 1 & 2 \end{pmatrix} = \begin{pmatrix} 34 & 57 \\ 46 & 77 \end{pmatrix}\)</p>
    
    <p>Therefore: \(C_{22} = \begin{pmatrix} 27 & 10 \\ 39 & 14 \end{pmatrix} + \begin{pmatrix} 34 & 57 \\ 46 & 77 \end{pmatrix} = \begin{pmatrix} 61 & 67 \\ 85 & 91 \end{pmatrix}\)</p>
    
    <p><strong>Final Divide-and-Conquer Result:</strong></p>
    <p>\[C = \begin{pmatrix} C_{11} & C_{12} \\ C_{21} & C_{22} \end{pmatrix} = \begin{pmatrix} 16 & 8 & 13 & 19 \\ 40 & 24 & 37 & 43 \\ 64 & 40 & 61 & 67 \\ 88 & 56 & 85 & 91 \end{pmatrix}\]</p>
  </div>

  <div class="example-box">
    <strong class="example-title">Verification: Brute Force Computation</strong>
    <p>Let's verify our result by computing the same multiplication using the standard \(O(n^3)\) algorithm. For each entry \(C[i][j] = \sum_{k=0}^{3} A[i][k] \cdot B[k][j]\):</p>
    
    <p><strong>First Row (i=0):</strong></p>
    <p>\(C[0][0] = 1(2) + 2(1) + 3(0) + 4(3) = 2 + 2 + 0 + 12 = 16\) ✓</p>
    <p>\(C[0][1] = 1(1) + 2(2) + 3(1) + 4(0) = 1 + 4 + 3 + 0 = 8\) ✓</p>
    <p>\(C[0][2] = 1(3) + 2(0) + 3(2) + 4(1) = 3 + 0 + 6 + 4 = 13\) ✓</p>
    <p>\(C[0][3] = 1(0) + 2(1) + 3(3) + 4(2) = 0 + 2 + 9 + 8 = 19\) ✓</p>
    
    <p><strong>Second Row (i=1):</strong></p>
    <p>\(C[1][0] = 5(2) + 6(1) + 7(0) + 8(3) = 10 + 6 + 0 + 24 = 40\) ✓</p>
    <p>\(C[1][1] = 5(1) + 6(2) + 7(1) + 8(0) = 5 + 12 + 7 + 0 = 24\) ✓</p>
    <p>\(C[1][2] = 5(3) + 6(0) + 7(2) + 8(1) = 15 + 0 + 14 + 8 = 37\) ✓</p>
    <p>\(C[1][3] = 5(0) + 6(1) + 7(3) + 8(2) = 0 + 6 + 21 + 16 = 43\) ✓</p>
    
    <p><strong>Third Row (i=2):</strong></p>
    <p>\(C[2][0] = 9(2) + 10(1) + 11(0) + 12(3) = 18 + 10 + 0 + 36 = 64\) ✓</p>
    <p>\(C[2][1] = 9(1) + 10(2) + 11(1) + 12(0) = 9 + 20 + 11 + 0 = 40\) ✓</p>
    <p>\(C[2][2] = 9(3) + 10(0) + 11(2) + 12(1) = 27 + 0 + 22 + 12 = 61\) ✓</p>
    <p>\(C[2][3] = 9(0) + 10(1) + 11(3) + 12(2) = 0 + 10 + 33 + 24 = 67\) ✓</p>
    
    <p><strong>Fourth Row (i=3):</strong></p>
    <p>\(C[3][0] = 13(2) + 14(1) + 15(0) + 16(3) = 26 + 14 + 0 + 48 = 88\) ✓</p>
    <p>\(C[3][1] = 13(1) + 14(2) + 15(1) + 16(0) = 13 + 28 + 15 + 0 = 56\) ✓</p>
    <p>\(C[3][2] = 13(3) + 14(0) + 15(2) + 16(1) = 39 + 0 + 30 + 16 = 85\) ✓</p>
    <p>\(C[3][3] = 13(0) + 14(1) + 15(3) + 16(2) = 0 + 14 + 45 + 32 = 91\) ✓</p>
    
    <p><strong>Both methods produce identical results!</strong> This confirms that our divide-and-conquer block formula correctly implements matrix multiplication by preserving the fundamental row-column dot product computation, just organized into larger blocks.</p>
  </div>

  <p>This idea leads the pseudocode like the following:</p>
  <ol>
    <li><strong>Base case:</strong> If current matrix size is smaller than some threshold, 
      use standard nested-loop multiplication</li>
    <li><strong>Recursive case:</strong> Divide current matrices into four quadrants of size \(n/2 \times n/2\)</li>
    <li><strong>Compute each result quadrant by combining two recursive products:</strong>
      <ul>
        <li><em>\(C_{11}:\)</em> Recursively compute \(A_{11} \times B_{11}\) and \(A_{12} \times B_{21}\), then add the results to get \(C_{11}\)</li>
        <li><em>\(C_{12}:\)</em> Recursively compute \(A_{11} \times B_{12}\) and \(A_{12} \times B_{22}\), then add the results to get \(C_{12}\)</li>
        <li><em>\(C_{21}:\)</em> Recursively compute \(A_{21} \times B_{11}\) and \(A_{22} \times B_{21}\), then add the results to get \(C_{21}\)</li>
        <li><em>\(C_{22}:\)</em> Recursively compute \(A_{21} \times B_{12}\) and \(A_{22} \times B_{22}\), then add the results to get \(C_{22}\)</li>
      </ul>
    </li>
  </ol>
  
  <p><strong>Key Features:</strong></p>
  <ul>
    <li>Makes 8 recursive calls total (2 for each result quadrant) with matrices of half the size</li>
    <li>Results accumulate directly into the final matrix C</li>
    <li>Can be implemented to avoid temporary matrices by working with subregions of the matrices</li>
    <li>Switches to standard O(n³) algorithm below threshold to avoid excessive recursion overhead</li>
  </ul>

  <p>The following interactive demonstration shows how the algorithm works step by step:</p>
  </section>

  <section id="demo">
  <div class="embeddedDemoContainer">
    <iframe class="embeddedDemo"
            src="/Algorithms/Content/Demos/Divide-and-Conquer/Matrix Multiplication Demo.html"
            allow="fullscreen"
            name="matrix-multiplication-demo">
    </iframe>
  </div>
  </section>

  <section id="code">
  <h2>Implementation in Java, C++, Python</h2>
  <p><strong>Key Implementation Details:</strong> These implementations use an <em>offset-based approach</em> rather than copying submatrices. Instead of creating new arrays for each recursive call, we pass indices that specify which portion of the original matrices to work with. The parameters <code>aRow, aCol, bRow, bCol, cRow, cCol</code> specify the top-left corners of the submatrices we're currently processing within the original matrices A, B, and C respectively.</p>
  
  <p><strong>Why Use Offsets?</strong> Copying submatrices would require \(O(n^2)\) time and space at each level of recursion, making the algorithm much less efficient. By using offsets, we work directly with the original matrices, accessing only the elements we need for each subproblem.</p>
  
  <p><strong>Threshold Optimization:</strong> We switch to standard multiplication when matrices become small (size ≤ 64) because the overhead of recursive function calls outweighs the benefits for tiny matrices. This threshold is typically determined empirically.</p>
  
  <div class="tab-group">
    <div class="tabs" role="tablist">
      <button id="tab-java" class="tablink active" data-lang="java" role="tab" aria-controls="java" aria-selected="true">Java</button>
      <button id="tab-cpp" class="tablink" data-lang="cpp" role="tab" aria-controls="cpp" aria-selected="false">C++</button>
      <button id="tab-python" class="tablink" data-lang="python" role="tab" aria-controls="python" aria-selected="false">Python</button>
    </div>
    <div id="java" class="code-container active" role="tabpanel" aria-labelledby="tab-java">
      <pre><code class="language-java">public class MatrixMultiplication {
    private static final int THRESHOLD = 64;
    
    /**
     * Multiplies two n×n matrices using divide-and-conquer.
     * Assumes n is a power of 2 for simplicity.
     */
    public static int[][] multiply(int[][] A, int[][] B) {
        int n = A.length;
        int[][] C = new int[n][n];
        multiplyRecursive(A, B, C, 0, 0, 0, 0, 0, 0, n);
        return C;
    }
    
    /**
     * Recursive helper method that multiplies submatrices using offsets.
     * 
     * @param A, B, C - the three matrices involved in C = A * B
     * @param aRow, aCol - top-left corner of submatrix in A
     * @param bRow, bCol - top-left corner of submatrix in B  
     * @param cRow, cCol - top-left corner of submatrix in C
     * @param size - size of the current submatrices (size × size)
     */
    private static void multiplyRecursive(int[][] A, int[][] B, int[][] C,
                                        int aRow, int aCol, int bRow, int bCol,
                                        int cRow, int cCol, int size) {
        if (size <= THRESHOLD) {
            // Base case: use standard O(n³) multiplication
            for (int i = 0; i < size; i++) {
                for (int j = 0; j < size; j++) {
                    for (int k = 0; k < size; k++) {
                        C[cRow + i][cCol + j] += A[aRow + i][aCol + k] * B[bRow + k][bCol + j];
                    }
                }
            }
            return;
        }
        
        int newSize = size / 2;
        
        // Compute C11 = A11*B11 + A12*B21
        // A11*B11: top-left of A times top-left of B
        multiplyRecursive(A, B, C, aRow, aCol, bRow, bCol, cRow, cCol, newSize);
        // A12*B21: top-right of A times bottom-left of B (add to C11)
        multiplyRecursive(A, B, C, aRow, aCol + newSize, bRow + newSize, bCol, cRow, cCol, newSize);
        
        // Compute C12 = A11*B12 + A12*B22
        multiplyRecursive(A, B, C, aRow, aCol, bRow, bCol + newSize, cRow, cCol + newSize, newSize);
        multiplyRecursive(A, B, C, aRow, aCol + newSize, bRow + newSize, bCol + newSize, cRow, cCol + newSize, newSize);
        
        // Compute C21 = A21*B11 + A22*B21
        multiplyRecursive(A, B, C, aRow + newSize, aCol, bRow, bCol, cRow + newSize, cCol, newSize);
        multiplyRecursive(A, B, C, aRow + newSize, aCol + newSize, bRow + newSize, bCol, cRow + newSize, cCol, newSize);
        
        // Compute C22 = A21*B12 + A22*B22
        multiplyRecursive(A, B, C, aRow + newSize, aCol, bRow, bCol + newSize, cRow + newSize, cCol + newSize, newSize);
        multiplyRecursive(A, B, C, aRow + newSize, aCol + newSize, bRow + newSize, bCol + newSize, cRow + newSize, cCol + newSize, newSize);
    }
}</code></pre>
    </div>
    <div id="cpp" class="code-container" role="tabpanel" aria-labelledby="tab-cpp">
      <pre><code class="language-cpp">#include <vector>
using namespace std;

class MatrixMultiplication {
private:
    static const int THRESHOLD = 64;
    
    /**
     * Recursive multiplication using offset-based approach.
     * Parameters specify which submatrix portion to work with.
     */
    static void multiplyRecursive(const vector<vector<int>>& A, const vector<vector<int>>& B,
                                vector<vector<int>>& C, int aRow, int aCol, int bRow, int bCol,
                                int cRow, int cCol, int size) {
        if (size <= THRESHOLD) {
            // Base case: standard multiplication for small matrices
            for (int i = 0; i < size; i++) {
                for (int j = 0; j < size; j++) {
                    for (int k = 0; k < size; k++) {
                        C[cRow + i][cCol + j] += A[aRow + i][aCol + k] * B[bRow + k][bCol + j];
                    }
                }
            }
            return;
        }
        
        int newSize = size / 2;
        
        // Each recursive call processes one of the 8 required submatrix products
        // The magic is in the offset arithmetic that selects the right quadrants
        
        // C11 = A11*B11 + A12*B21
        multiplyRecursive(A, B, C, aRow, aCol, bRow, bCol, cRow, cCol, newSize);
        multiplyRecursive(A, B, C, aRow, aCol + newSize, bRow + newSize, bCol, cRow, cCol, newSize);
        
        // C12 = A11*B12 + A12*B22  
        multiplyRecursive(A, B, C, aRow, aCol, bRow, bCol + newSize, cRow, cCol + newSize, newSize);
        multiplyRecursive(A, B, C, aRow, aCol + newSize, bRow + newSize, bCol + newSize, cRow, cCol + newSize, newSize);
        
        // C21 = A21*B11 + A22*B21
        multiplyRecursive(A, B, C, aRow + newSize, aCol, bRow, bCol, cRow + newSize, cCol, newSize);
        multiplyRecursive(A, B, C, aRow + newSize, aCol + newSize, bRow + newSize, bCol, cRow + newSize, cCol, newSize);
        
        // C22 = A21*B12 + A22*B22
        multiplyRecursive(A, B, C, aRow + newSize, aCol, bRow, bCol + newSize, cRow + newSize, cCol + newSize, newSize);
        multiplyRecursive(A, B, C, aRow + newSize, aCol + newSize, bRow + newSize, bCol + newSize, cRow + newSize, cCol + newSize, newSize);
    }
    
public:
    static vector<vector<int>> multiply(const vector<vector<int>>& A, const vector<vector<int>>& B) {
        int n = A.size();
        vector<vector<int>> C(n, vector<int>(n, 0));
        multiplyRecursive(A, B, C, 0, 0, 0, 0, 0, 0, n);
        return C;
    }
};</code></pre>
    </div>
    <div id="python" class="code-container" role="tabpanel" aria-labelledby="tab-python">
      <pre><code class="language-python">class MatrixMultiplication:
    THRESHOLD = 64
    
    @staticmethod
    def multiply(A, B):
        """
        Multiply two n×n matrices using divide-and-conquer.
        Assumes n is a power of 2.
        """
        n = len(A)
        C = [[0] * n for _ in range(n)]
        MatrixMultiplication._multiply_recursive(A, B, C, 0, 0, 0, 0, 0, 0, n)
        return C
    
    @staticmethod
    def _multiply_recursive(A, B, C, a_row, a_col, b_row, b_col, c_row, c_col, size):
        """
        The offset parameters (a_row, a_col, etc.) tell us which submatrix
        we're working with. For example:
        - (a_row, a_col) is the top-left corner of our current A submatrix
        - size determines how large the submatrix is (size × size)
        """
        if size <= MatrixMultiplication.THRESHOLD:
            # Base case: use straightforward nested loops
            for i in range(size):
                for j in range(size):
                    for k in range(size):
                        C[c_row + i][c_col + j] += A[a_row + i][a_col + k] * B[b_row + k][b_col + j]
            return
        
        new_size = size // 2
        
        # The block formula C11 = A11*B11 + A12*B21 becomes two recursive calls:
        # 1) A11*B11: multiply top-left quadrants
        MatrixMultiplication._multiply_recursive(A, B, C, a_row, a_col, b_row, b_col, c_row, c_col, new_size)
        # 2) A12*B21: multiply top-right of A with bottom-left of B, ADD to same result location
        MatrixMultiplication._multiply_recursive(A, B, C, a_row, a_col + new_size, b_row + newSize, b_col, cRow, cCol, new_size)
        
        # C12 = A11*B12 + A12*B22 (result goes to top-right of C)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row, a_col, b_row, bCol + newSize, cRow, cCol + newSize, new_size)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row, aCol + new_size, bRow + newSize, bCol + newSize, cRow, cCol + newSize, new_size)
        
        # C21 = A21*B11 + A22*B21 (result goes to bottom-left of C)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row + new_size, a_col, b_row, bCol, cRow + new_size, cCol, newSize)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row + new_size, a_col + new_size, b_row + newSize, bCol, cRow + new_size, cCol, newSize)
        
        # C22 = A21*B12 + A22*B22 (result goes to bottom-right of C)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row + new_size, a_col, b_row, bCol + newSize, cRow + new_size, cCol + new_size, newSize)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row + new_size, a_col + new_size, b_row + newSize, bCol + newSize, cRow + new_size, cCol + new_size, newSize)</code></pre>
    </div>
  </div>
  </section>

  <section id="analysis">
  <h2>Time/Space Analysis</h2>
  <p><strong>Time Complexity:</strong> This basic divide-and-conquer approach has the same \(O(n^3)\) complexity as standard matrix multiplication. The recurrence relation is \(T(n) = 8T(n/2) + O(n^2)\) where the \(O(n^2)\) term comes from the additions needed to combine results. By the Master Theorem (case 1: \(a = 8\), \(b = 2\), \(f(n) = O(n^2)\), and \(n^{\log_2 8} = n^3\)), we get \(T(n) = O(n^3)\). However, this approach has better cache locality due to its access patterns and provides a foundation for more advanced algorithms like Strassen's method.</p>
  
  <p><strong>Space Complexity:</strong> \(O(\log n)\) for the recursion stack (since we recurse \(\log_2 n\) levels deep), plus \(O(n^2)\) for the result matrix. The key advantage is that we don't create temporary submatrices at each level—we work directly with the original arrays using offsets.</p>
  
  <p><strong>Handling Non-Power-of-2 Sizes:</strong> For matrices where \(n\) is not a power of 2, we can pad the matrices with zeros to reach the next power of 2, then trim the result. This adds some overhead but allows the algorithm to work with any size. Alternatively, more complex implementations can handle odd sizes by carefully managing the base cases.</p>
  </section>
  
  
  <section id="variations">
  <h2>Variations/Improvements</h2>
  <p>
    <strong>Strassen's Algorithm:</strong> Reduces the number of recursive multiplications from 8 to 7 using clever algebraic identities, achieving \(O(n^{2.807})\) complexity. Better for very large matrices but has higher constant factors and is more complex to implement.
  </p>
  <p>
    <strong>Cache-Oblivious Algorithms:</strong> Optimize the divide-and-conquer approach to work efficiently across all levels of the memory hierarchy without knowing specific cache parameters.
  </p>
  <p>
    <strong>Parallel Implementation:</strong> The recursive structure naturally supports parallelization, where different quadrant multiplications can be computed simultaneously on multiple cores.
  </p>
  </section>

  <section id="links">
  <h2>Links to Resources</h2>
  <ul>
    <li><a href="https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm#Divide-and-conquer_algorithm" target="_blank">Wikipedia: Matrix Multiplication Algorithms</a> Comprehensive overview of various matrix multiplication approaches</li>
    <li><a href="https://web.stanford.edu/class/cs97si/06-basic-data-structures.pdf" target="_blank">Stanford CS Guide</a> Mathematical foundations and algorithmic analysis</li>
    <li><a href="https://www.geeksforgeeks.org/divide-and-conquer-set-5-strassens-matrix-multiplication/" target="_blank">GeeksforGeeks: Strassen's Algorithm</a> Implementation details for the advanced variant</li>
  </ul>
  </section>

  <section id="reading-questions">
    <h2>Reading Comprehension Questions</h2>
    <ol>
      <li><strong>Complexity Analysis:</strong> Why does the basic divide-and-conquer matrix multiplication have the same time complexity as the standard algorithm, and what advantage does it provide?</li>
      <li><strong>Base Case:</strong> Why is it important to use a threshold and switch to standard multiplication for small matrices rather than recursing all the way down to 1×1 matrices?</li>
      <li><strong>Matrix Partitioning:</strong> Explain how the mathematical property of block matrix multiplication enables the divide-and-conquer approach to work correctly.</li>
    </ol>
    <button id="toggleAnswers" class="show-answer" aria-expanded="false">Show Answers</button>
    <div id="answers" class="answer" hidden>
      <ol>
        <li><strong>Answer:</strong> Both have \(O(n^3)\) complexity because the recurrence \(T(n) = 8T(n/2) + O(n^2)\) still yields cubic time. However, the divide-and-conquer approach has better cache locality and memory access patterns, and provides a foundation for more advanced algorithms like Strassen's method.</li>
        <li><strong>Answer:</strong> Using a threshold (typically 64-128) avoids excessive recursion overhead for small matrices. The constant factors and function call overhead would make tiny recursive calls inefficient compared to simple nested loops.</li>
        <li><strong>Answer:</strong> Block matrix multiplication preserves the associativity and distributive properties of matrix multiplication. When matrices are partitioned into blocks, the multiplication rule \((AB)_{ij} = \sum_k A_{ik}B_{kj}\) still applies where the indices now represent blocks rather than individual elements.</li>
      </ol>
    </div>
  </section>

  <section id="activities">
    <h2>In-Class Activities</h2>
    <ol>
      <li><strong>Hand Trace Exercise:</strong> Work through a 4×4 matrix multiplication by hand using the divide-and-conquer approach, showing how it decomposes into 2×2 submatrix operations.</li>
      <li><strong>Threshold Analysis:</strong> Implement both versions and experimentally determine the optimal threshold value for switching to standard multiplication on your system.</li>
      <li><strong>Memory Access Pattern:</strong> Analyze and compare the cache miss patterns between standard matrix multiplication and the divide-and-conquer approach using performance profiling tools.</li>
    </ol>
  </section>

  <section id="problems">
    <h2>Homework Problems</h2>
    <ol>
      <li><strong>Non-Square Matrices:</strong> Modify the algorithm to handle non-square matrices and matrices whose dimensions are not powers of 2.</li>
      <li><strong>Memory Optimization:</strong> Implement an in-place version that minimizes additional memory allocation during the recursive calls.</li>
      <li><strong>Strassen Implementation:</strong> Research and implement Strassen's algorithm, comparing its performance against the standard divide-and-conquer approach for various matrix sizes.</li>
      <li><strong>Parallel Version:</strong> Design a parallel version of the algorithm using threads or a parallel computing framework, analyzing the speedup achieved.</li>
    </ol>
  </section>

</body>
</html>
      <li><strong>Parallel Version:</strong> Design a parallel version of the algorithm using threads or a parallel computing framework, analyzing the speedup achieved.</li>
    </ol>
  </section>

</body>
</html>
      <li><strong>Memory Optimization:</strong> Implement an in-place version that minimizes additional memory allocation during the recursive calls.</li>
      <li><strong>Strassen Implementation:</strong> Research and implement Strassen's algorithm, comparing its performance against the standard divide-and-conquer approach for various matrix sizes.</li>
      <li><strong>Parallel Version:</strong> Design a parallel version of the algorithm using threads or a parallel computing framework, analyzing the speedup achieved.</li>
    </ol>
  </section>

</body>
</html>
