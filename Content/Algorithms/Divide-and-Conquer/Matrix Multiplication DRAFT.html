<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Matrix Multiplication (Divide and Conquer)</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="/Algorithms/scripts/chapterScripts.js"></script>
  <link rel="stylesheet" href="/Algorithms/css/style.css">
  <link rel="stylesheet" href="/Algorithms/css/chapter.css">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-DQ5LVZVFDC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-DQ5LVZVFDC');
  </script>
</head>
<body>
  <h1>Matrix Multiplication (Divide and Conquer)</h1>

  <section id="problem-solved">
  <h2>Problem Solved</h2>
  <p>
    Matrix Multiplication (Divide and Conquer) solves the
    <a class="problem" href="?path=Problems%2FFoundational%2FMatrix%20Multiplication">Matrix Multiplication</a>
    problem using a divide-and-conquer approach that can be more efficient than the standard algorithm for large matrices.
  </p>
  </section>

  <section id="design">
  <h2>Design and Strategy</h2>
  <p>
    The divide-and-conquer approach to matrix multiplication recursively breaks down the problem of multiplying two n×n matrices into smaller subproblems. Instead of using the standard \(O(n^3)\) algorithm that computes each entry using a dot product, we divide each matrix into four quadrants and use the mathematical property that matrix multiplication can be expressed in terms of operations on these quadrants.
  </p>
  
  <p><strong>Size Restriction:</strong> For simplicity, we assume \(n = 2^k\) for some integer \(k\), so matrices can be evenly divided. This ensures each recursive call works with matrices of size \(n/2 \times n/2\). Matrices of odd sizes or non-power-of-2 dimensions can be handled by padding with zeros to the next power of 2, though this introduces some overhead.</p>

  <p>
    For two n×n matrices A and B, we partition them as:
    \[A = \begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix}, \quad B = \begin{pmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{pmatrix}\]
  </p>
  
  <p>
    The product C = A × B can then be computed as:
    \[C = \begin{pmatrix} C_{11} & C_{12} \\ C_{21} & C_{22} \end{pmatrix}\]
    where:
    \[C_{11} = A_{11}B_{11} + A_{12}B_{21}\]
    \[C_{12} = A_{11}B_{12} + A_{12}B_{22}\]
    \[C_{21} = A_{21}B_{11} + A_{22}B_{21}\]
    \[C_{22} = A_{21}B_{12} + A_{22}B_{22}\]
  </p>

  <p><strong>Why This Formula Works:</strong> The key insight is that matrix multiplication follows the same rules whether we think of entries as scalars or as blocks (submatrices). When we multiply \(A \times B\), each entry \(C_{ij}\) is computed as the dot product of row \(i\) from \(A\) and column \(j\) from \(B\). When we partition the matrices into blocks, this dot product naturally splits:</p>
  
  <ul>
    <li>For \(C_{11}\): We need entries from the top-left quadrant of \(C\). These come from dot products of the first \(n/2\) rows of \(A\) with the first \(n/2\) columns of \(B\). This gives us \((A_{11}|A_{12}) \cdot \binom{B_{11}}{B_{21}} = A_{11}B_{11} + A_{12}B_{21}\).</li>
    <li>Similarly, \(C_{12}\) uses the first \(n/2\) rows of \(A\) with the last \(n/2\) columns of \(B\): \(A_{11}B_{12} + A_{12}B_{22}\).</li>
    <li>The same pattern holds for \(C_{21}\) and \(C_{22}\) using the bottom half of \(A\)'s rows.</li>
  </ul>

  <p><strong>Concrete Example:</strong> Consider multiplying two 4×4 matrices:</p>
  
  <p>
    \[A = \begin{pmatrix} 1 & 2 & 3 & 4 \\ 5 & 6 & 7 & 8 \\ 9 & 10 & 11 & 12 \\ 13 & 14 & 15 & 16 \end{pmatrix} = \begin{pmatrix} \begin{pmatrix} 1 & 2 \\ 5 & 6 \end{pmatrix} & \begin{pmatrix} 3 & 4 \\ 7 & 8 \end{pmatrix} \\ \begin{pmatrix} 9 & 10 \\ 13 & 14 \end{pmatrix} & \begin{pmatrix} 11 & 12 \\ 15 & 16 \end{pmatrix} \end{pmatrix}\]
  </p>
  
  <p>When we compute \(C_{11} = A_{11}B_{11} + A_{12}B_{21}\), we're computing the contribution to the top-left 2×2 block of the result from all the necessary row-column interactions. This preserves the fundamental definition of matrix multiplication while allowing us to work with larger blocks.</p>

  <p><strong>Algorithm Steps:</strong></p>
  <ol>
    <li>If matrix size n ≤ threshold (typically 64-128), use standard multiplication</li>
    <li>Divide matrices A and B into four n/2 × n/2 submatrices</li>
    <li>Recursively compute the 8 matrix products needed for the result quadrants</li>
    <li>Add the appropriate products to form each quadrant of the result</li>
    <li>Combine quadrants to form the final result matrix</li>
  </ol>

  <p>The following interactive demonstration shows how the algorithm works step by step:</p>
  </section>

  <section id="demo">
  <div class="embeddedDemoContainer">
    <iframe class="embeddedDemo"
            src="/Algorithms/Content/Demos/Divide-and-Conquer/Matrix Multiplication Demo.html"
            allow="fullscreen"
            name="matrix-multiplication-demo">
    </iframe>
  </div>
  </section>

  <section id="code">
  <h2>Implementation in Java, C++, Python</h2>
  <p><strong>Key Implementation Details:</strong> These implementations use an <em>offset-based approach</em> rather than copying submatrices. Instead of creating new arrays for each recursive call, we pass indices that specify which portion of the original matrices to work with. The parameters <code>aRow, aCol, bRow, bCol, cRow, cCol</code> specify the top-left corners of the submatrices we're currently processing within the original matrices A, B, and C respectively.</p>
  
  <p><strong>Why Use Offsets?</strong> Copying submatrices would require \(O(n^2)\) time and space at each level of recursion, making the algorithm much less efficient. By using offsets, we work directly with the original matrices, accessing only the elements we need for each subproblem.</p>
  
  <p><strong>Threshold Optimization:</strong> We switch to standard multiplication when matrices become small (size ≤ 64) because the overhead of recursive function calls outweighs the benefits for tiny matrices. This threshold is typically determined empirically.</p>
  
  <div class="tab-group">
    <div class="tabs" role="tablist">
      <button id="tab-java" class="tablink active" data-lang="java" role="tab" aria-controls="java" aria-selected="true">Java</button>
      <button id="tab-cpp" class="tablink" data-lang="cpp" role="tab" aria-controls="cpp" aria-selected="false">C++</button>
      <button id="tab-python" class="tablink" data-lang="python" role="tab" aria-controls="python" aria-selected="false">Python</button>
    </div>
    <div id="java" class="code-container active" role="tabpanel" aria-labelledby="tab-java">
      <pre><code class="language-java">public class MatrixMultiplication {
    private static final int THRESHOLD = 64;
    
    /**
     * Multiplies two n×n matrices using divide-and-conquer.
     * Assumes n is a power of 2 for simplicity.
     */
    public static int[][] multiply(int[][] A, int[][] B) {
        int n = A.length;
        int[][] C = new int[n][n];
        multiplyRecursive(A, B, C, 0, 0, 0, 0, 0, 0, n);
        return C;
    }
    
    /**
     * Recursive helper method that multiplies submatrices using offsets.
     * 
     * @param A, B, C - the three matrices involved in C = A * B
     * @param aRow, aCol - top-left corner of submatrix in A
     * @param bRow, bCol - top-left corner of submatrix in B  
     * @param cRow, cCol - top-left corner of submatrix in C
     * @param size - size of the current submatrices (size × size)
     */
    private static void multiplyRecursive(int[][] A, int[][] B, int[][] C,
                                        int aRow, int aCol, int bRow, int bCol,
                                        int cRow, int cCol, int size) {
        if (size <= THRESHOLD) {
            // Base case: use standard O(n³) multiplication
            for (int i = 0; i < size; i++) {
                for (int j = 0; j < size; j++) {
                    for (int k = 0; k < size; k++) {
                        C[cRow + i][cCol + j] += A[aRow + i][aCol + k] * B[bRow + k][bCol + j];
                    }
                }
            }
            return;
        }
        
        int newSize = size / 2;
        
        // Compute C11 = A11*B11 + A12*B21
        // A11*B11: top-left of A times top-left of B
        multiplyRecursive(A, B, C, aRow, aCol, bRow, bCol, cRow, cCol, newSize);
        // A12*B21: top-right of A times bottom-left of B (add to C11)
        multiplyRecursive(A, B, C, aRow, aCol + newSize, bRow + newSize, bCol, cRow, cCol, newSize);
        
        // Compute C12 = A11*B12 + A12*B22
        multiplyRecursive(A, B, C, aRow, aCol, bRow, bCol + newSize, cRow, cCol + newSize, newSize);
        multiplyRecursive(A, B, C, aRow, aCol + newSize, bRow + newSize, bCol + newSize, cRow, cCol + newSize, newSize);
        
        // Compute C21 = A21*B11 + A22*B21
        multiplyRecursive(A, B, C, aRow + newSize, aCol, bRow, bCol, cRow + newSize, cCol, newSize);
        multiplyRecursive(A, B, C, aRow + newSize, aCol + newSize, bRow + newSize, bCol, cRow + newSize, cCol, newSize);
        
        // Compute C22 = A21*B12 + A22*B22
        multiplyRecursive(A, B, C, aRow + newSize, aCol, bRow, bCol + newSize, cRow + newSize, cCol + newSize, newSize);
        multiplyRecursive(A, B, C, aRow + newSize, aCol + newSize, bRow + newSize, bCol + newSize, cRow + newSize, cCol + newSize, newSize);
    }
}</code></pre>
    </div>
    <div id="cpp" class="code-container" role="tabpanel" aria-labelledby="tab-cpp">
      <pre><code class="language-cpp">#include <vector>
using namespace std;

class MatrixMultiplication {
private:
    static const int THRESHOLD = 64;
    
    /**
     * Recursive multiplication using offset-based approach.
     * Parameters specify which submatrix portion to work with.
     */
    static void multiplyRecursive(const vector<vector<int>>& A, const vector<vector<int>>& B,
                                vector<vector<int>>& C, int aRow, int aCol, int bRow, int bCol,
                                int cRow, int cCol, int size) {
        if (size <= THRESHOLD) {
            // Base case: standard multiplication for small matrices
            for (int i = 0; i < size; i++) {
                for (int j = 0; j < size; j++) {
                    for (int k = 0; k < size; k++) {
                        C[cRow + i][cCol + j] += A[aRow + i][aCol + k] * B[bRow + k][bCol + j];
                    }
                }
            }
            return;
        }
        
        int newSize = size / 2;
        
        // Each recursive call processes one of the 8 required submatrix products
        // The magic is in the offset arithmetic that selects the right quadrants
        
        // C11 = A11*B11 + A12*B21
        multiplyRecursive(A, B, C, aRow, aCol, bRow, bCol, cRow, cCol, newSize);
        multiplyRecursive(A, B, C, aRow, aCol + newSize, bRow + newSize, bCol, cRow, cCol, newSize);
        
        // C12 = A11*B12 + A12*B22  
        multiplyRecursive(A, B, C, aRow, aCol, bRow, bCol + newSize, cRow, cCol + newSize, newSize);
        multiplyRecursive(A, B, C, aRow, aCol + newSize, bRow + newSize, bCol + newSize, cRow, cCol + newSize, newSize);
        
        // C21 = A21*B11 + A22*B21
        multiplyRecursive(A, B, C, aRow + newSize, aCol, bRow, bCol, cRow + newSize, cCol, newSize);
        multiplyRecursive(A, B, C, aRow + newSize, aCol + newSize, bRow + newSize, bCol, cRow + newSize, cCol, newSize);
        
        // C22 = A21*B12 + A22*B22
        multiplyRecursive(A, B, C, aRow + newSize, aCol, bRow, bCol + newSize, cRow + newSize, cCol + newSize, newSize);
        multiplyRecursive(A, B, C, aRow + newSize, aCol + newSize, bRow + newSize, bCol + newSize, cRow + newSize, cCol + newSize, newSize);
    }
    
public:
    static vector<vector<int>> multiply(const vector<vector<int>>& A, const vector<vector<int>>& B) {
        int n = A.size();
        vector<vector<int>> C(n, vector<int>(n, 0));
        multiplyRecursive(A, B, C, 0, 0, 0, 0, 0, 0, n);
        return C;
    }
};</code></pre>
    </div>
    <div id="python" class="code-container" role="tabpanel" aria-labelledby="tab-python">
      <pre><code class="language-python">class MatrixMultiplication:
    THRESHOLD = 64
    
    @staticmethod
    def multiply(A, B):
        """
        Multiply two n×n matrices using divide-and-conquer.
        Assumes n is a power of 2.
        """
        n = len(A)
        C = [[0] * n for _ in range(n)]
        MatrixMultiplication._multiply_recursive(A, B, C, 0, 0, 0, 0, 0, 0, n)
        return C
    
    @staticmethod
    def _multiply_recursive(A, B, C, a_row, a_col, b_row, b_col, c_row, c_col, size):
        """
        The offset parameters (a_row, a_col, etc.) tell us which submatrix
        we're working with. For example:
        - (a_row, a_col) is the top-left corner of our current A submatrix
        - size determines how large the submatrix is (size × size)
        """
        if size <= MatrixMultiplication.THRESHOLD:
            # Base case: use straightforward nested loops
            for i in range(size):
                for j in range(size):
                    for k in range(size):
                        C[c_row + i][c_col + j] += A[a_row + i][a_col + k] * B[b_row + k][b_col + j]
            return
        
        new_size = size // 2
        
        # The block formula C11 = A11*B11 + A12*B21 becomes two recursive calls:
        # 1) A11*B11: multiply top-left quadrants
        MatrixMultiplication._multiply_recursive(A, B, C, a_row, a_col, b_row, b_col, c_row, c_col, new_size)
        # 2) A12*B21: multiply top-right of A with bottom-left of B, ADD to same result location
        MatrixMultiplication._multiply_recursive(A, B, C, a_row, a_col + new_size, b_row + new_size, b_col, c_row, c_col, new_size)
        
        # C12 = A11*B12 + A12*B22 (result goes to top-right of C)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row, a_col, b_row, b_col + new_size, c_row, c_col + new_size, new_size)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row, a_col + new_size, b_row + newSize, b_col + newSize, cRow, cCol + newSize, newSize)
        
        # C21 = A21*B11 + A22*B21 (result goes to bottom-left of C)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row + new_size, a_col, b_row, bCol, cRow + new_size, cCol, newSize)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row + new_size, a_col + new_size, b_row + newSize, bCol, cRow + new_size, cCol, newSize)
        
        # C22 = A21*B12 + A22*B22 (result goes to bottom-right of C)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row + new_size, a_col, b_row, bCol + new_size, cRow + new_size, cCol + new_size, newSize)
        MatrixMultiplication._multiply_recursive(A, B, C, a_row + new_size, a_col + new_size, b_row + newSize, bCol + newSize, cRow + new_size, cCol + newSize, newSize)</code></pre>
    </div>
  </div>
  </section>

  <section id="analysis">
  <h2>Time/Space Analysis</h2>
  <p><strong>Time Complexity:</strong> This basic divide-and-conquer approach has the same \(O(n^3)\) complexity as standard matrix multiplication. The recurrence relation is \(T(n) = 8T(n/2) + O(n^2)\) where the \(O(n^2)\) term comes from the additions needed to combine results. By the Master Theorem (case 1: \(a = 8\), \(b = 2\), \(f(n) = O(n^2)\), and \(n^{\log_2 8} = n^3\)), we get \(T(n) = O(n^3)\). However, this approach has better cache locality due to its access patterns and provides a foundation for more advanced algorithms like Strassen's method.</p>
  
  <p><strong>Space Complexity:</strong> \(O(\log n)\) for the recursion stack (since we recurse \(\log_2 n\) levels deep), plus \(O(n^2)\) for the result matrix. The key advantage is that we don't create temporary submatrices at each level—we work directly with the original arrays using offsets.</p>
  
  <p><strong>Handling Non-Power-of-2 Sizes:</strong> For matrices where \(n\) is not a power of 2, we can pad the matrices with zeros to reach the next power of 2, then trim the result. This adds some overhead but allows the algorithm to work with any size. Alternatively, more complex implementations can handle odd sizes by carefully managing the base cases.</p>
  </section>
  
  
  <section id="variations">
  <h2>Variations/Improvements</h2>
  <p>
    <strong>Strassen's Algorithm:</strong> Reduces the number of recursive multiplications from 8 to 7 using clever algebraic identities, achieving \(O(n^{2.807})\) complexity. Better for very large matrices but has higher constant factors and is more complex to implement.
  </p>
  <p>
    <strong>Cache-Oblivious Algorithms:</strong> Optimize the divide-and-conquer approach to work efficiently across all levels of the memory hierarchy without knowing specific cache parameters.
  </p>
  <p>
    <strong>Parallel Implementation:</strong> The recursive structure naturally supports parallelization, where different quadrant multiplications can be computed simultaneously on multiple cores.
  </p>
  </section>

  <section id="links">
  <h2>Links to Resources</h2>
  <ul>
    <li><a href="https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm#Divide-and-conquer_algorithm" target="_blank">Wikipedia: Matrix Multiplication Algorithms</a> Comprehensive overview of various matrix multiplication approaches</li>
    <li><a href="https://web.stanford.edu/class/cs97si/06-basic-data-structures.pdf" target="_blank">Stanford CS Guide</a> Mathematical foundations and algorithmic analysis</li>
    <li><a href="https://www.geeksforgeeks.org/divide-and-conquer-set-5-strassens-matrix-multiplication/" target="_blank">GeeksforGeeks: Strassen's Algorithm</a> Implementation details for the advanced variant</li>
  </ul>
  </section>

  <section id="reading-questions">
    <h2>Reading Comprehension Questions</h2>
    <ol>
      <li><strong>Complexity Analysis:</strong> Why does the basic divide-and-conquer matrix multiplication have the same time complexity as the standard algorithm, and what advantage does it provide?</li>
      <li><strong>Base Case:</strong> Why is it important to use a threshold and switch to standard multiplication for small matrices rather than recursing all the way down to 1×1 matrices?</li>
      <li><strong>Matrix Partitioning:</strong> Explain how the mathematical property of block matrix multiplication enables the divide-and-conquer approach to work correctly.</li>
    </ol>
    <button id="toggleAnswers" class="show-answer" aria-expanded="false">Show Answers</button>
    <div id="answers" class="answer" hidden>
      <ol>
        <li><strong>Answer:</strong> Both have \(O(n^3)\) complexity because the recurrence \(T(n) = 8T(n/2) + O(n^2)\) still yields cubic time. However, the divide-and-conquer approach has better cache locality and memory access patterns, and provides a foundation for more advanced algorithms like Strassen's method.</li>
        <li><strong>Answer:</strong> Using a threshold (typically 64-128) avoids excessive recursion overhead for small matrices. The constant factors and function call overhead would make tiny recursive calls inefficient compared to simple nested loops.</li>
        <li><strong>Answer:</strong> Block matrix multiplication preserves the associativity and distributive properties of matrix multiplication. When matrices are partitioned into blocks, the multiplication rule \((AB)_{ij} = \sum_k A_{ik}B_{kj}\) still applies where the indices now represent blocks rather than individual elements.</li>
      </ol>
    </div>
  </section>

  <section id="activities">
    <h2>In-Class Activities</h2>
    <ol>
      <li><strong>Hand Trace Exercise:</strong> Work through a 4×4 matrix multiplication by hand using the divide-and-conquer approach, showing how it decomposes into 2×2 submatrix operations.</li>
      <li><strong>Threshold Analysis:</strong> Implement both versions and experimentally determine the optimal threshold value for switching to standard multiplication on your system.</li>
      <li><strong>Memory Access Pattern:</strong> Analyze and compare the cache miss patterns between standard matrix multiplication and the divide-and-conquer approach using performance profiling tools.</li>
    </ol>
  </section>

  <section id="problems">
    <h2>Homework Problems</h2>
    <ol>
      <li><strong>Non-Square Matrices:</strong> Modify the algorithm to handle non-square matrices and matrices whose dimensions are not powers of 2.</li>
      <li><strong>Memory Optimization:</strong> Implement an in-place version that minimizes additional memory allocation during the recursive calls.</li>
      <li><strong>Strassen Implementation:</strong> Research and implement Strassen's algorithm, comparing its performance against the standard divide-and-conquer approach for various matrix sizes.</li>
      <li><strong>Parallel Version:</strong> Design a parallel version of the algorithm using threads or a parallel computing framework, analyzing the speedup achieved.</li>
    </ol>
  </section>

</body>
</html>
